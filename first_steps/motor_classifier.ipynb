{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199f3688-c4a4-4652-865c-740ab265e6aa",
   "metadata": {},
   "source": [
    "# Train a 3D Convolutional Neural Network (3dCNN) to classify motor tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d87eac6-0be1-4c62-b097-753fc82f131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from delphi import mni_template\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from delphi.networks.ConvNets import BrainStateClassifier3d\n",
    "from delphi.utils.datasets import NiftiDataset\n",
    "from delphi.utils.tools import ToTensor, compute_accuracy, convert_wandb_config, read_config, z_transform_volume\n",
    "from delphi.utils.plots import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5ca42e-df0c-46ef-a1cf-771b1fa3d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    import random\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    g = torch.Generator()  # can be used in pytorch dataloaders for reproducible sample selection when shuffle=True\n",
    "    g.manual_seed(seed)\n",
    "\n",
    "    return g\n",
    "\n",
    "g = set_random_seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf46778-196b-4de0-a1a8-095a5224be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_plots(y_true, y_pred, y_prob, class_labels, dataset):\n",
    "    wandb.log({\n",
    "        f\"{dataset}-ROC\": wandb.plot.roc_curve(y_true=y_true, y_probas=y_prob, labels=class_labels, title=f\"{dataset}-ROC\"),\n",
    "        f\"{dataset}-PR\": wandb.plot.pr_curve(y_true=y_true, y_probas=y_prob, labels=class_labels, title=f\"{dataset}-PR\"),\n",
    "        f\"{dataset}-ConfMat\": wandb.plot.confusion_matrix(y_true=y_true, preds=y_pred, class_names=class_labels, title=f\"{dataset}-ConfMat\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd57314-7a34-4084-b558-78df9c211420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_wandb_env():\n",
    "    exclude = {\n",
    "        \"WANDB_PROJECT\",\n",
    "        \"WANDB_ENTITY\",\n",
    "        \"WANDB_API_KEY\",\n",
    "    }\n",
    "    for k, v in os.environ.items():\n",
    "        if k.startswith(\"WANDB_\") and k not in exclude:\n",
    "            del os.environ[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acec5605-27f4-452f-88d1-07a0f54d69b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['footleft', 'footright', 'handleft', 'handright', 'tongue']\n"
     ]
    }
   ],
   "source": [
    "class_labels = sorted([\"handleft\", \"handright\", \"footleft\", \"footright\", \"tongue\"])\n",
    "print(class_labels)\n",
    "\n",
    "data_test = NiftiDataset(\"../t-maps/test\", class_labels, 0, device=DEVICE, transform=ToTensor())\n",
    "\n",
    "# we will split the train dataset into a train (80%) and validation (20%) set.\n",
    "data_train_full = NiftiDataset(\"../t-maps/train\", class_labels, 0, device=DEVICE, transform=ToTensor(), shuffle_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0b297-b18d-4e6d-b965-8f32551c649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the wandb sweep config\n",
    "# os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_ENTITY'] = \"philis893\" # this is my wandb account name. This can also be a group name, for example\n",
    "os.environ['WANDB_PROJECT'] = \"thesis\" # this is simply the project name where we want to store the sweep logs and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8cc5c-121f-40b0-92f2-15a4df670785",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hp = read_config(\"hyperparameter.yaml\")\n",
    "hp = read_config(\"hyperparameter.yaml\")\n",
    "\n",
    "num_folds = 10\n",
    "run = 0\n",
    "input_dims = (91, 109, 91)\n",
    "\n",
    "# we want one stratified shuffled split\n",
    "sss = StratifiedShuffleSplit(n_splits=num_folds, test_size=0.2, random_state=2020)\n",
    "\n",
    "for fold, (idx_train, idx_valid) in enumerate(sss.split(data_train_full.data, data_train_full.labels)):\n",
    "    reset_wandb_env()\n",
    "    wandb_kwargs = {\n",
    "        \"entity\": \"philis893\",\n",
    "        \"project\": \"thesis\",\n",
    "        \"group\": \"first-steps-motor\",\n",
    "        \"name\": f\"motor-classifier_fold-{fold:02d}\",\n",
    "        \"job_type\": \"CV-motor\" if num_folds > 1 else \"train\",\n",
    "    }\n",
    "\n",
    "    data_train = torch.utils.data.Subset(data_train_full, idx_train)\n",
    "    data_valid = torch.utils.data.Subset(data_train_full, idx_valid)\n",
    "    \n",
    "    save_name = os.path.join(\"models\", wandb_kwargs[\"name\"])\n",
    "    if os.path.exists(save_name):\n",
    "        continue\n",
    "        \n",
    "    g = set_random_seed(2020 + fold + run)\n",
    "        \n",
    "    with wandb.init(config=hp, **wandb_kwargs) as run:\n",
    "        \n",
    "        model_cfg = {\n",
    "            \"channels\": [1, 8, 16, 32, 64],\n",
    "            \"lin_neurons\": [128, 64],\n",
    "            \"pooling_kernel\": 2,\n",
    "            \"kernel_size\": run.config.kernel_size,\n",
    "            \"dropout\": run.config.dropout,\n",
    "        }\n",
    "        model = BrainStateClassifier3d(input_dims, len(class_labels), model_cfg)\n",
    "        model.to(DEVICE);\n",
    "        \n",
    "        dl_train = DataLoader(data_train, batch_size=run.config.batch_size, shuffle=True, generator=g)\n",
    "        dl_valid = DataLoader(data_valid, batch_size=run.config.batch_size, shuffle=True, generator=g)\n",
    "        dl_test = DataLoader(data_test, batch_size=run.config.batch_size, shuffle=False, generator=g)\n",
    "\n",
    "        best_loss, best_acc = 100, 0\n",
    "        loss_acc = []\n",
    "        train_stats, valid_stats = [], []\n",
    "\n",
    "        # loop for the above set number of epochs\n",
    "        for epoch in range(run.config.epochs):\n",
    "            _, _ = model.fit(dl_train, lr=run.config.learning_rate, device=DEVICE)\n",
    "\n",
    "            # for validating or testing set the network into evaluation mode such that layers like dropout are not active\n",
    "            with torch.no_grad():\n",
    "                tloss, tstats = model.fit(dl_train, device=DEVICE, train=False)\n",
    "                vloss, vstats = model.fit(dl_valid, device=DEVICE, train=False)\n",
    "\n",
    "            # the model.fit() method has 2 output parameters: loss, stats = model.fit()\n",
    "            # the first parameter is simply the loss for each sample\n",
    "            # the second parameter is a matrix of n_classes+2-by-n_samples\n",
    "            # the first n_classes columns are the output probabilities of the model per class\n",
    "            # the second to last column (i.e., [:, -2]) represents the real labels\n",
    "            # the last column (i.e., [:, -1]) represents the predicted labels\n",
    "            tacc = compute_accuracy(tstats[:, -2], tstats[:, -1])\n",
    "            vacc = compute_accuracy(vstats[:, -2], vstats[:, -1])\n",
    "\n",
    "            loss_acc.append(pd.DataFrame([[tloss, vloss, tacc, vacc]],\n",
    "                                         columns=[\"train_loss\", \"valid_loss\", \"train_acc\", \"valid_acc\"]))\n",
    "\n",
    "            train_stats.append(pd.DataFrame(tstats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]]))\n",
    "            train_stats[epoch][\"epoch\"] = epoch\n",
    "            valid_stats.append(pd.DataFrame(vstats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]]))\n",
    "            valid_stats[epoch][\"epoch\"] = epoch\n",
    "\n",
    "            wandb.log({\n",
    "                \"train_acc\": tacc, \"train_loss\": tloss,\n",
    "                \"valid_acc\": vacc, \"valid_loss\": vloss\n",
    "            }, step=epoch)\n",
    "\n",
    "            print('Epoch=%03d, train_loss=%2.3f, train_acc=%1.3f, valid_loss=%2.3f, valid_acc=%1.3f' % \n",
    "                 (epoch, tloss, tacc, vloss, vacc))\n",
    "\n",
    "            if (vacc >= best_acc) and (vloss <= best_loss):\n",
    "                # assign the new best values\n",
    "                best_acc, best_loss = vacc, vloss\n",
    "                wandb.run.summary[\"best_valid_accuracy\"] = best_acc\n",
    "                wandb.run.summary[\"best_valid_epoch\"] = epoch\n",
    "                # save the current best model\n",
    "                model.save(save_name)\n",
    "                # plot some graphs for the validation data\n",
    "                wandb_plots(vstats[:, -2], vstats[:, -1], vstats[:, :-2], class_labels, \"valid\")\n",
    "\n",
    "\n",
    "        # save the files\n",
    "        full_df = pd.concat(loss_acc)\n",
    "        full_df.to_csv(os.path.join(save_name, \"loss_acc_curves.csv\"), index=False)\n",
    "        full_df = pd.concat(train_stats)\n",
    "        full_df.to_csv(os.path.join(save_name, \"train_stats.csv\"), index=False)\n",
    "        full_df = pd.concat(valid_stats)\n",
    "        full_df.to_csv(os.path.join(save_name, \"valid_stats.csv\"), index=False)\n",
    "\n",
    "        # EVALUATE THE MODEL ON THE TEST DATA\n",
    "        with torch.no_grad():\n",
    "            testloss, teststats = model.fit(dl_test, train=False)\n",
    "        testacc = compute_accuracy(teststats[:, -2], teststats[:, -1])\n",
    "        wandb.run.summary[\"test_accuracy\"] = testacc\n",
    "\n",
    "        wandb.log({\"test_accuracy\": testacc, \"test_loss\": testloss})\n",
    "        wandb_plots(teststats[:, -2], teststats[:, -1], teststats[:, :-2], class_labels, \"test\")\n",
    "\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f0bd8-c7d2-4bce-8466-3fb18dc9e612",
   "metadata": {},
   "source": [
    "# Run the Layer-wise Relevance Propagation (LRP) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b71458-d3aa-44ae-8f3b-7b3e771988ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delphi.utils.tools import save_in_mni\n",
    "from zennit import composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878bc2b4-f68e-4e04-8c49-a39ab6a0aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the LRP algorithm and save the resulting LRP maps somewhere.\n",
    "shape = (1, 1, 91, 109, 91)\n",
    "\n",
    "composite_kwargs = {\n",
    "    'low': -1 * torch.ones(*shape, device=torch.device(\"cpu\")),  # the lowest and ...\n",
    "    'high': 1 * torch.ones(*shape, device=torch.device(\"cpu\")),  # the highest pixel value for ZBox\n",
    "}\n",
    "# In this line I am telling zennit what kind of rule I want to use and supply\n",
    "# some arguments. \n",
    "attributor = composites.COMPOSITES['epsilon_gamma_box'](**composite_kwargs)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "for fold in range(10):\n",
    "# load the trained network\n",
    "    model = BrainStateClassifier3d(f\"models/motor-classifier_fold-{fold:02d}\")\n",
    "    model.eval()\n",
    "    model.to(torch.device(\"cpu\"));\n",
    "\n",
    "    out_dir_name = f\"lrp/epsgamma_fold-{fold:02d}\"\n",
    "    if not os.path.exists(out_dir_name):\n",
    "        os.mkdir(out_dir_name)\n",
    "\n",
    "    for j in range(len(class_labels)):\n",
    "\n",
    "        print(f\"Running LRP on {class_labels[j]}\")\n",
    "        dl = DataLoader(\n",
    "            NiftiDataset('../t-maps/test', [class_labels[j]], 0, device=torch.device(\"cpu\"), transform=ToTensor()),\n",
    "            batch_size=20, shuffle=False, num_workers=0\n",
    "        )\n",
    "\n",
    "        for i, (volume, target) in enumerate(dl):\n",
    "\n",
    "            volume.requires_grad = True\n",
    "            grad_dummy = torch.eye(model.config['n_classes'], device=torch.device(\"cpu\"))[target]\n",
    "\n",
    "            with attributor.context(model) as modified_model:\n",
    "\n",
    "                output = modified_model(volume)\n",
    "                attribution, = torch.autograd.grad(output, volume, grad_outputs=grad_dummy)\n",
    "                subject_lrp = np.moveaxis(attribution.squeeze().detach().numpy(), 0, -1)\n",
    "                subject_lrp = z_transform_volume(subject_lrp)\n",
    "                avg_lrp = subject_lrp.mean(axis=-1)\n",
    "\n",
    "        save_in_mni(subject_lrp, os.path.join(out_dir_name, '%s.nii.gz' % class_labels[j]))\n",
    "        #save_in_mni(avg_lrp, os.path.join(out_dir_name, 'avg_%s.nii.gz' % class_labels[j]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08888549-a2c2-498b-86ce-01654820747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us visualize the average LRP maps\n",
    "# Brain_Data from the nltools toolbox allows us to visualize brain maps quit nicely\n",
    "from nltools.data import Brain_Data\n",
    "\n",
    "files = sorted(glob(f\"motor-mapper-lrp-epsgamma/handleft.nii.gz\"))\n",
    "#files = sorted(glob(\"../t-maps/test/handleft/*.nii.gz\"))\n",
    "dat = Brain_Data(files)\n",
    "dat.iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038645d5-cc5d-4acb-9f9f-504de6e123f8",
   "metadata": {},
   "source": [
    "# SecondLevel GLM analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a2d620-0cc0-42f6-9fef-02248702da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2a1cbd-3bc3-4d37-aa53-b5dda722e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a0e240-af56-47c3-90bd-a8b75a2713f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the real images\n",
    "test_img_files = sorted(glob(\"../t-maps/test/*/*.nii.gz\"))\n",
    "images = load_img(test_img_files)\n",
    "real = np.repeat([0,1,2,3,4], 20)\n",
    "#real = np.repeat([2,3], 20)\n",
    "\n",
    "# load the relevance images\n",
    "fold = 1\n",
    "relevance_files = sorted(glob(f\"lrp/epsgamma_fold-{fold:02d}/*nii.gz\"))\n",
    "relevance_maps = load_img(relevance_files)\n",
    "\n",
    "mask = load_img(mni_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869feb8-e91f-4211-8a7b-6f66082e6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_design_matrix, plot_contrast_matrix\n",
    "n_subs = 20\n",
    "n = len(test_img_files)\n",
    "design_matrix = {}\n",
    "\n",
    "for label in range(len(class_labels)):\n",
    "    regressor = np.repeat(np.eye(len(class_labels))[label], n_subs)\n",
    "    design_matrix[f'{class_labels[label]}'] = regressor\n",
    "               \n",
    "design_matrix['lh_vs_rh'] = np.repeat([0, 0, 1, -1, 0], n_subs)\n",
    "design_matrix['lf_vs_rf'] = np.repeat([1, -1, 0, 0, 0], n_subs)\n",
    "design_matrix['t_vs_all'] = np.repeat([-.25, -.25, -.25, -.25, 1], n_subs)\n",
    "design_matrix['f_vs_h'] = np.repeat([.5, .5, -.5, -.5, 0], n_subs)\n",
    "design_matrix['intercept'] = np.ones(n)\n",
    "\n",
    "for sub in range(n_subs):\n",
    "    regressor = np.tile(np.eye(n_subs)[sub], len(class_labels))\n",
    "    design_matrix[f'sub-{sub}'] = regressor\n",
    "\n",
    "df_design_matrix = pd.DataFrame(design_matrix)\n",
    "plot_design_matrix(df_design_matrix, rescale=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7dac4-135f-44ba-aa51-edfb89312cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "glm_orig = SecondLevelModel(smoothing_fwhm=None, mask_img=mask)\n",
    "glm_orig.fit([nilearn.image.index_img(images, i) for i in range(n)], design_matrix=df_design_matrix)\n",
    "\n",
    "glm_lrp = SecondLevelModel(smoothing_fwhm=None, mask_img=mask)\n",
    "glm_lrp.fit([nilearn.image.index_img(relevance_maps , i) for i in range(n)], design_matrix=df_design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d29e5-f53b-4c9e-a81f-633a04f23aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts = [\"footleft\", \"footright\", \"handleft\", \"handright\", \"tongue\"]\n",
    "#\"lh_vs_rh\", \"lf_vs_rf\", \"t_vs_all\", \"f_vs_h\"]\n",
    "\n",
    "for c, contrast in enumerate(contrasts):\n",
    "    maps_orig = glm_orig.compute_contrast(contrast, output_type=\"all\")\n",
    "    maps_lrp = glm_lrp.compute_contrast(contrast, output_type=\"all\")\n",
    "\n",
    "    fig, axes = plt.subplots(1,2,figsize=(18,6))\n",
    "    nilearn.plotting.plot_glass_brain(maps_orig['z_score'], colorbar=True, plot_abs=False, axes=axes[0]);\n",
    "    axes[0].set_title(f\"{contrast}-orig\")\n",
    "    nilearn.plotting.plot_glass_brain(maps_lrp['z_score'], colorbar=True, plot_abs=False, axes=axes[1]);\n",
    "    axes[1].set_title(f\"{contrast}-lrp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810f293-3d70-4cc4-aead-056f505036da",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TEST OCCLUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "febe0ee9-d5da-4246-b34d-3f56c7899a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delphi.utils.tools import occlude_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936b2ea-90e7-4f45-8ee4-8adb8e7a1cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from config file models/motor-classifier_fold-00/config.yaml\n",
      "Loading from config file models/motor-classifier_fold-01/config.yaml\n",
      "Loading from config file models/motor-classifier_fold-02/config.yaml\n",
      "Loading from config file models/motor-classifier_fold-03/config.yaml\n",
      "Loading from config file models/motor-classifier_fold-04/config.yaml\n"
     ]
    }
   ],
   "source": [
    "percentages = np.array([0, .01, .1, .2, .5, .75, 1, 5, 10, 20, 30, 50, 75])\n",
    "accs = np.zeros((8, len(percentages)))\n",
    "n_voxel = np.zeros_like(percentages)\n",
    "\n",
    "\n",
    "for f in range(8):\n",
    "    # load the trained network\n",
    "    model = BrainStateClassifier3d(f\"models/motor-classifier_fold-{f:02d}\")\n",
    "    model.eval()\n",
    "    model.to(torch.device(\"cpu\"));\n",
    "    \n",
    "    relevance_files = sorted(glob(f\"lrp/epsgamma_fold-{fold:02d}/*nii.gz\"))\n",
    "    relevance_maps = load_img(relevance_files)\n",
    "\n",
    "    for i, frac in enumerate(percentages):\n",
    "        occluded, n_voxel[f] = occlude_images(images, relevance_maps, mask, fraction=frac, get_fdata=True)\n",
    "        occluded = np.moveaxis(occluded, -1, 0)\n",
    "        occluded = torch.tensor(occluded).unsqueeze(1)\n",
    "        pred = np.argmax(model(occluded.float()).detach().cpu().numpy(), axis=1)\n",
    "        accs[f, i] = compute_accuracy(real, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fe1b3-d9e9-4159-b746-4107ddf8461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = accs[:7].mean(axis=0)\n",
    "sd_acc = accs[:7].std(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "ax.errorbar(np.log(percentages), mean_acc, yerr=sd_acc, marker=\"o\", linewidth=3, capsize=5, capthick=2);\n",
    "ax.scatter(np.repeat(np.log(percentages), 7), accs[:7].transpose(), marker=\"o\", alpha=.2, color=\"black\");\n",
    "ax.set_xticks(np.log(percentages)), ax.set_xticklabels(percentages)\n",
    "ax.hlines(.2, ax.get_xlim()[0], ax.get_xlim()[1], color=\"black\", linestyle=\"--\")\n",
    "ax.set_title('Occlusion effect'), ax.set_xlabel('Percent occlusion'), ax.set_ylabel('accuracy')\n",
    "ax.spines['top'].set_visible(False), ax.spines['right'].set_visible(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd48852d-f2c6-439a-9ffe-4d76a30c6218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.051303100964311, 4.76362102851253)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.get_xlim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f7862-e86e-401f-b555-79f37fb26d57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
