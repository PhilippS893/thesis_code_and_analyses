{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199f3688-c4a4-4652-865c-740ab265e6aa",
   "metadata": {},
   "source": [
    "# Train a 3D Convolutional Neural Network (3dCNN) to classify motor tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512daf9-457e-4fb1-8f7d-b02a17edddca",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>In this notebook we create and train a 3D-Convolutional Neural Network which learns to classify different patterns of whole-brain fMRI statistical parameters (t-scores). In this first approach our goal is to train a classifier that can reliably distinguish between such whole-brain patterns for five limb movements (i.e., left/right hand, left/right foot, and tongue).\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d87eac6-0be1-4c62-b097-753fc82f131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from delphi import mni_template\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from delphi.networks.ConvNets import BrainStateClassifier3d\n",
    "from delphi.utils.datasets import NiftiDataset\n",
    "from delphi.utils.tools import ToTensor, compute_accuracy, convert_wandb_config, read_config, z_transform_volume\n",
    "from delphi.utils.plots import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b2335-28be-41c8-addf-9b9788f39cb2",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>To make sure that we obtain (almost) the same results for each execution we set the random seed of multiple different librabries (i.e., torch, random, numpy)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5ca42e-df0c-46ef-a1cf-771b1fa3d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    import random\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    g = torch.Generator()  # can be used in pytorch dataloaders for reproducible sample selection when shuffle=True\n",
    "    g.manual_seed(seed)\n",
    "\n",
    "    return g\n",
    "\n",
    "g = set_random_seed(2020) # the project started in the year 2020, hence the seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ba199-6808-4f87-8acc-87c339be166f",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>We use a library called <a href=\"https://wandb.ai\">weights and biases</a> to keep track of our networks performances and, as the name suggests, their weigths and biases. The function below uses some of its functionallity to print receiver-operating-characteristics, precision-recall, and confusion matrices. (See <a href=\"https://wandb.ai/philis893/thesis?workspace=user-philis893\">https://wandb.ai/philis893/thesis?workspace=user-philis893)</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf46778-196b-4de0-a1a8-095a5224be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_plots(y_true, y_pred, y_prob, class_labels, dataset):\n",
    "    r\"\"\"\n",
    "    Function to plot receiver-operating-characteristics, precision-recall curves, and confusion matrices\n",
    "    in the w&b online platform.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: list of true labels\n",
    "    y_pred: list of predicted labels\n",
    "    y_prob: probability values of the network prediction\n",
    "    class_labels: the names of the classes to predict\n",
    "    dataset: string; name of the current dataset\n",
    "    \"\"\"\n",
    "    wandb.log({\n",
    "        f\"{dataset}-ROC\": wandb.plot.roc_curve(y_true=y_true, y_probas=y_prob, labels=class_labels, title=f\"{dataset}-ROC\"),\n",
    "        f\"{dataset}-PR\": wandb.plot.pr_curve(y_true=y_true, y_probas=y_prob, labels=class_labels, title=f\"{dataset}-PR\"),\n",
    "        f\"{dataset}-ConfMat\": wandb.plot.confusion_matrix(y_true=y_true, preds=y_pred, class_names=class_labels, title=f\"{dataset}-ConfMat\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd57314-7a34-4084-b558-78df9c211420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_wandb_env():\n",
    "    exclude = {\n",
    "        \"WANDB_PROJECT\",\n",
    "        \"WANDB_ENTITY\",\n",
    "        \"WANDB_API_KEY\",\n",
    "    }\n",
    "    for k, v in os.environ.items():\n",
    "        if k.startswith(\"WANDB_\") and k not in exclude:\n",
    "            del os.environ[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df7fee-a2ef-47fc-a91f-b28d6670b434",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73ca8fb-a9c1-424a-beeb-c91ddfd1b0be",
   "metadata": {},
   "source": [
    "In this section, we define and initialize our required variables. We first need to define which classes we want to predict, i.e., the conditions of the motor mapper. We then define a PyTorch dataset; in this case `NiftiDataset` is a custom written Dataset-Class (see https://github.com/PhilippS893/delphi). As is common practice in machine learning projects, we split our data into a training and validation dataset (ratio=80 to 20, respectively).\n",
    "\n",
    "Note: In case it is necessary to create a null-model, i.e., a neural network that is trained on data where the labels are randomized, one can set the parameter `shuffe_labels=False` to `True`. This is usually done to have a baseline for the null hypothesis that \"everything is random\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acec5605-27f4-452f-88d1-07a0f54d69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = sorted([\"handleft\", \"handright\", \"footleft\", \"footright\", \"tongue\"])\n",
    "\n",
    "data_test = NiftiDataset(\"../t-maps/test\", class_labels, 0, device=DEVICE, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34364974-90ec-4926-b384-297fd4b0a1b5",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>We now set some parameters required by w&b to properly store information about our trained neural networks.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c0b297-b18d-4e6d-b965-8f32551c649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the wandb sweep config\n",
    "# os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_ENTITY'] = \"philis893\" # this is my wandb account name. This can also be a group name, for example\n",
    "os.environ['WANDB_PROJECT'] = \"thesis\" # this is simply the project name where we want to store the sweep logs and plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69bd8c8-3f32-4293-8cb9-8ef47b87d297",
   "metadata": {},
   "source": [
    "## Training the neural network(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8371a07-a271-4b50-8812-5e6c26673735",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>In this first approach, we estimated what parameters we could use for our 3d-CNN from existing literature. We make use of some functionality, e.g., the function \"read_config\", I wrote for the \"delphi\" toolbox (see https://github.com/PhilippS893/delphi). This function can read .yaml files with the formatting as below:</p>\n",
    "\n",
    "The contents of `hyperparameter.yaml`: <br>\n",
    "`kernel_size: 5`<br>\n",
    "`batch_size: 4`<br>\n",
    "`dropout: .5`<br>\n",
    "`learning_rate: 0.00001`<br>\n",
    "`epochs: 60`<br>\n",
    "`channels: [1, 8, 16, 32, 64]`<br>\n",
    "`lin_neurons: [128, 64]`<br>\n",
    "`pooling_kernel: 2`<br>\n",
    "\n",
    "The function `read_config` will return a dictionary variable containing all keyword-value pairs as set in the `hyperparameter.yaml`. We do this, because the `delphi` toolbox was written with dictionaries as configuration variables in mind and because we can easily submit dictionaries to `w&b` to keep track of such parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "431b5777-3c39-47b0-9c5d-58cc31d75169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(run, fold, data_train, data_valid, data_test, hp, class_labels, shuffled_labels=False):\n",
    "    reset_wandb_env()\n",
    "    \n",
    "    job_name = \"CV-shuffled\" if shuffled_labels else \"CV-real\"\n",
    "    wandb_kwargs = {\n",
    "        \"entity\": os.environ['WANDB_ENTITY'],\n",
    "        \"project\": os.environ['WANDB_PROJECT'],\n",
    "        \"group\": \"first-steps\",\n",
    "        \"name\": f\"motor_fold-{fold:02d}\",\n",
    "        \"job_type\": job_name if num_folds > 1 else \"train\",\n",
    "    }\n",
    "    \n",
    "    save_name = os.path.join(\"models\", job_name, wandb_kwargs[\"name\"])\n",
    "    if os.path.exists(save_name):\n",
    "        return\n",
    "    \n",
    "    # we adjust the random seed here to ensure that each run of each fold has a unique seed!\n",
    "    g = set_random_seed(2020 + fold + run)\n",
    "    \n",
    "    # we now use the wandb context to track the training and evaluation process.\n",
    "    # all settings and changes will be reset at the beginning of the fold-loop. (see line 11)\n",
    "    with wandb.init(config=hp, **wandb_kwargs) as run:\n",
    "        \n",
    "        # please note that this conversion is unnecessary if not using w&b!\n",
    "        model_cfg = convert_wandb_config(run.config, BrainStateClassifier3d._REQUIRED_PARAMS)\n",
    "        \n",
    "        # setup a model with the parameters given in model_cfg\n",
    "        model = BrainStateClassifier3d(input_dims, len(class_labels), model_cfg)\n",
    "        model.to(DEVICE);\n",
    "        \n",
    "        model.config[\"class_labels\"] = class_labels\n",
    "        \n",
    "        dl_train = DataLoader(data_train, batch_size=run.config.batch_size, shuffle=True, generator=g)\n",
    "        dl_valid = DataLoader(data_valid, batch_size=run.config.batch_size, shuffle=True, generator=g)\n",
    "        dl_test = DataLoader(data_test, batch_size=run.config.batch_size, shuffle=False, generator=g)\n",
    "\n",
    "        best_loss, best_acc = 100, 0\n",
    "        loss_acc = []\n",
    "        train_stats, valid_stats = [], []\n",
    "\n",
    "        # loop for the above set number of epochs\n",
    "        for epoch in range(run.config.epochs):\n",
    "            _, _ = model.fit(dl_train, lr=run.config.learning_rate)\n",
    "\n",
    "            # for validating or testing set the network into evaluation mode such that layers like dropout are not active\n",
    "            with torch.no_grad():\n",
    "                tloss, tstats = model.fit(dl_train, train=False)\n",
    "                vloss, vstats = model.fit(dl_valid, train=False)\n",
    "\n",
    "            # the model.fit() method has 2 output parameters: loss, stats = model.fit()\n",
    "            # the first parameter is simply the loss for each sample\n",
    "            # the second parameter is a matrix of n_classes+2-by-n_samples\n",
    "            # the first n_classes columns are the output probabilities of the model per class\n",
    "            # the second to last column (i.e., [:, -2]) represents the real labels\n",
    "            # the last column (i.e., [:, -1]) represents the predicted labels\n",
    "            tacc = compute_accuracy(tstats[:, -2], tstats[:, -1])\n",
    "            vacc = compute_accuracy(vstats[:, -2], vstats[:, -1])\n",
    "\n",
    "            loss_acc.append(pd.DataFrame([[tloss, vloss, tacc, vacc]],\n",
    "                                         columns=[\"train_loss\", \"valid_loss\", \"train_acc\", \"valid_acc\"]))\n",
    "\n",
    "            train_stats.append(pd.DataFrame(tstats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]]))\n",
    "            train_stats[epoch][\"epoch\"] = epoch\n",
    "            valid_stats.append(pd.DataFrame(vstats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]]))\n",
    "            valid_stats[epoch][\"epoch\"] = epoch\n",
    "\n",
    "            wandb.log({\n",
    "                \"train_acc\": tacc, \"train_loss\": tloss,\n",
    "                \"valid_acc\": vacc, \"valid_loss\": vloss\n",
    "            }, step=epoch)\n",
    "\n",
    "            print('Epoch=%03d, train_loss=%2.3f, train_acc=%1.3f, valid_loss=%2.3f, valid_acc=%1.3f' % \n",
    "                 (epoch, tloss, tacc, vloss, vacc))\n",
    "\n",
    "            if (vacc >= best_acc) and (vloss <= best_loss):\n",
    "                # assign the new best values\n",
    "                best_acc, best_loss = vacc, vloss\n",
    "                wandb.run.summary[\"best_valid_accuracy\"] = best_acc\n",
    "                wandb.run.summary[\"best_valid_epoch\"] = epoch\n",
    "                # save the current best model\n",
    "                model.save(save_name)\n",
    "                # plot some graphs for the validation data\n",
    "                wandb_plots(vstats[:, -2], vstats[:, -1], vstats[:, :-2], class_labels, \"valid\")\n",
    "\n",
    "\n",
    "        # save the files\n",
    "        full_df = pd.concat(loss_acc)\n",
    "        full_df.to_csv(os.path.join(save_name, \"loss_acc_curves.csv\"), index=False)\n",
    "        full_df = pd.concat(train_stats)\n",
    "        full_df.to_csv(os.path.join(save_name, \"train_stats.csv\"), index=False)\n",
    "        full_df = pd.concat(valid_stats)\n",
    "        full_df.to_csv(os.path.join(save_name, \"valid_stats.csv\"), index=False)\n",
    "\n",
    "        # EVALUATE THE MODEL ON THE TEST DATA\n",
    "        with torch.no_grad():\n",
    "            testloss, teststats = model.fit(dl_test, train=False)\n",
    "        testacc = compute_accuracy(teststats[:, -2], teststats[:, -1])\n",
    "        df_test = pd.DataFrame(teststats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]])\n",
    "        df_test.to_csv(os.path.join(save_name, \"test_stats.csv\"), index=False)\n",
    "        wandb.run.summary[\"test_accuracy\"] = testacc\n",
    "\n",
    "        wandb.log({\"test_accuracy\": testacc, \"test_loss\": testloss})\n",
    "        wandb_plots(teststats[:, -2], teststats[:, -1], teststats[:, :-2], class_labels, \"test\")\n",
    "\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c595940-a263-4257-95be-38f895269e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = read_config(\"hyperparameter.yaml\")\n",
    "\n",
    "num_folds = 10 # we decided to run a 10-fold cross-validation scheme\n",
    "run = 0 # in case you decide to do multiple runs of the cross-validation scheme\n",
    "input_dims = (91, 109, 91) # these are the 3D input dimension of our whole-brain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a40287c-57a6-43f3-a812-38b6ecea3cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f88ea-db23-4fc6-a4a3-b59243f2a4fd",
   "metadata": {},
   "source": [
    "### Run cross-validation training using correct labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd352b-3993-4986-8d8c-425dda5ecae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/phisei/Documents/phd/thesis_code_and_analyses/first_steps/wandb/run-20230210_165248-2dfya7oh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/philis893/thesis/runs/2dfya7oh\" target=\"_blank\">motor_fold-00</a></strong> to <a href=\"https://wandb.ai/philis893/thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01228475570678711,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987ae80713c54ea48b1bafa8e7b4fffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we will split the train dataset into a train (80%) and validation (20%) set.\n",
    "data_train_full = NiftiDataset(\"../t-maps/train\", class_labels, 0, device=DEVICE, \n",
    "                               transform=ToTensor(), shuffle_labels=False)\n",
    "\n",
    "# we want a stratified shuffled split\n",
    "sss = StratifiedShuffleSplit(n_splits=num_folds, test_size=0.2, random_state=2020)\n",
    "\n",
    "for fold, (idx_train, idx_valid) in enumerate(sss.split(data_train_full.data, data_train_full.labels)):\n",
    "    data_train = torch.utils.data.Subset(data_train_full, idx_train)\n",
    "    data_valid = torch.utils.data.Subset(data_train_full, idx_valid)\n",
    "    train_network(run, fold, data_train, data_valid, data_test, hp, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e6f2f-8ae9-4b21-b11b-5085418d7f25",
   "metadata": {},
   "source": [
    "### Run cross-validation training using shuffled labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b378f-67ee-4936-a219-e3a419acb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will split the train dataset into a train (80%) and validation (20%) set.\n",
    "data_train_full = NiftiDataset(\"../t-maps/train\", class_labels, 20, device=DEVICE, \n",
    "                               transform=ToTensor(), shuffle_labels=True)\n",
    "\n",
    "# we want a stratified shuffled split\n",
    "sss = StratifiedShuffleSplit(n_splits=num_folds, test_size=0.2, random_state=2020)\n",
    "\n",
    "for fold, (idx_train, idx_valid) in enumerate(sss.split(data_train_full.data, data_train_full.labels)):\n",
    "    data_train = torch.utils.data.Subset(data_train_full, idx_train)\n",
    "    data_valid = torch.utils.data.Subset(data_train_full, idx_valid)\n",
    "    train_network(run, fold, data_train, data_valid, data_test, hp, class_labels, shuffled_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2236e-a9b5-41e9-b409-014fe5aa31b4",
   "metadata": {},
   "source": [
    "## Analyzing the network performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "016a9b7d-b8df-4d2b-a94c-293d2251b568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from config file models/CV-motor-real/motor-classifier_fold-00/config.yaml\n",
      "BrainStateClassifier3d(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (SM): Softmax(dim=1)\n",
      "  (conv): Sequential(\n",
      "    (convlayer0): Sequential(\n",
      "      (0): Conv3d(1, 8, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (convlayer1): Sequential(\n",
      "      (0): Conv3d(8, 16, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (convlayer2): Sequential(\n",
      "      (0): Conv3d(16, 32, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (convlayer3): Sequential(\n",
      "      (0): Conv3d(32, 64, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (lin): Sequential(\n",
      "    (lin0): Sequential(\n",
      "      (0): Linear(in_features=9600, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (lin1): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02063298225402832,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d5a31907904dc69c01b280734aaaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x150 and 9600x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 18\u001b[0m     _ , stats \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stats\u001b[38;5;241m.\u001b[39mtolist(), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m*\u001b[39mclass_labels, \u001b[38;5;241m*\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m     21\u001b[0m df_test\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(fold, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_stats.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/phd/delphi/delphi/networks/Base.py:131\u001b[0m, in \u001b[0;36mTemplateModel.fit\u001b[0;34m(self, train_data, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_data: DataLoader, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/phd/delphi/delphi/utils/train_fns.py:76\u001b[0m, in \u001b[0;36mstandard_train\u001b[0;34m(model, train_data, loss_fn, optimizer, lr, device, train, **optimizer_kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m     74\u001b[0m         p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# forward pass through model\u001b[39;00m\n\u001b[1;32m     78\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs\u001b[38;5;241m.\u001b[39msqueeze(), labels\u001b[38;5;241m.\u001b[39msqueeze())  \u001b[38;5;66;03m# calculate loss\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# in this statement we check if the network is currently in training mode,\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# which means, that every layer in the network has the required_grad flag set\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# to True. This in turn means that the backpropagation algorithm is executed.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# If the model, however, is not in training mode we do not want to exectue\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# the backward pass and we also do not want to store the so-called pytorch graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/delphi/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/phd/delphi/delphi/networks/ConvNets.py:170\u001b[0m, in \u001b[0;36mBrainStateClassifier3d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, linlayer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 170\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlinlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# pass the input through the last linlayer but do not use dropout!\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/delphi/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/delphi/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/delphi/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/delphi/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x150 and 9600x128)"
     ]
    }
   ],
   "source": [
    "# compute the test classification accuracy of the folds\n",
    "label_condition = ['real', 'shuffled']\n",
    "\n",
    "df = pd.DataFrame(columns=label_condition)\n",
    "\n",
    "for i, c in enumerate(label_condition):\n",
    "    \n",
    "    # get the folds\n",
    "    folds = sorted(glob(os.path.join(f\"models/CV-motor-{c}\", \"*fold*\")))\n",
    "    \n",
    "    for j, fold in enumerate(folds):\n",
    "        \n",
    "        model = BrainStateClassifier3d(fold)\n",
    "        model.to(DEVICE)\n",
    "        print(model)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _ , stats = model.fit(data_test, train=False)\n",
    "        \n",
    "        df_test = pd.DataFrame(stats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]])\n",
    "        df_test.to_csv(os.path.join(fold, \"test_stats.csv\"), index=False)\n",
    "        acc = compute_accuracy(stats[:, -2], stats[:, -1])\n",
    "        df.insert(j, c, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90541e8-abf2-4540-893e-ba8187764cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f0bd8-c7d2-4bce-8466-3fb18dc9e612",
   "metadata": {},
   "source": [
    "## Investigate what information was deemed relevant (XAI)\n",
    "### Run the Layer-wise Relevance Propagation (LRP) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b71458-d3aa-44ae-8f3b-7b3e771988ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delphi.utils.tools import save_in_mni\n",
    "from zennit import composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878bc2b4-f68e-4e04-8c49-a39ab6a0aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the LRP algorithm and save the resulting LRP maps somewhere.\n",
    "shape = (1, 1, 91, 109, 91)\n",
    "\n",
    "composite_kwargs = {\n",
    "    'low': -5 * torch.ones(*shape, device=torch.device(\"cpu\")),  # the lowest and ...\n",
    "    'high': 5 * torch.ones(*shape, device=torch.device(\"cpu\")),  # the highest pixel value for ZBox\n",
    "}\n",
    "# In this line I am telling zennit what kind of rule I want to use and supply\n",
    "# some arguments. \n",
    "attributor = composites.COMPOSITES['epsilon_gamma_box'](**composite_kwargs)\n",
    "\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "\n",
    "for fold in range(4, 10):\n",
    "# load the trained network\n",
    "    model = BrainStateClassifier3d(f\"models/CV-motor/motor-classifier_fold-{fold:02d}\")\n",
    "    model.eval()\n",
    "    model.to(torch.device(\"cpu\"));\n",
    "\n",
    "    out_dir_name = f\"lrp/epsgamma_fold-{fold:02d}\"\n",
    "    if not os.path.exists(out_dir_name):\n",
    "        os.mkdir(out_dir_name)\n",
    "\n",
    "    for j in range(len(class_labels)):\n",
    "\n",
    "        print(f\"Running LRP on {class_labels[j]}\")\n",
    "        \n",
    "        out_fname = os.path.join(out_dir_name, '%s_test.nii.gz' % class_labels[j])\n",
    "        if os.path.isfile(out_fname):\n",
    "            print(f\"{out_fname} already exists. Skipping\")\n",
    "            continue\n",
    "        \n",
    "        dl = DataLoader(\n",
    "            NiftiDataset('../t-maps/test', [class_labels[j]], 0, device=torch.device(\"cpu\"), transform=ToTensor()),\n",
    "            batch_size=20, shuffle=False, num_workers=0\n",
    "        )\n",
    "\n",
    "        for i, (volume, target) in enumerate(dl):\n",
    "\n",
    "            volume.requires_grad = True\n",
    "            grad_dummy = torch.eye(model.config['n_classes'], device=torch.device(\"cpu\"))[target]\n",
    "\n",
    "            with attributor.context(model) as modified_model:\n",
    "\n",
    "                output = modified_model(volume)\n",
    "                attribution, = torch.autograd.grad(output, volume, grad_outputs=grad_dummy)\n",
    "                subject_lrp = np.moveaxis(attribution.squeeze().detach().numpy(), 0, -1)\n",
    "                subject_lrp = z_transform_volume(subject_lrp)\n",
    "                avg_lrp = subject_lrp.mean(axis=-1)\n",
    "\n",
    "        save_in_mni(subject_lrp, out_fname)\n",
    "        #save_in_mni(avg_lrp, os.path.join(out_dir_name, 'avg_%s_test.nii.gz' % class_labels[j]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08888549-a2c2-498b-86ce-01654820747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us visualize the average LRP maps\n",
    "# Brain_Data from the nltools toolbox allows us to visualize brain maps quit nicely\n",
    "from nltools.data import Brain_Data\n",
    "\n",
    "#files = sorted(glob(f\"motor-mapper-lrp-epsgamma/handleft.nii.gz\"))\n",
    "fold = 1\n",
    "files = sorted(glob(f\"lrp/epsgamma_fold-{fold:02d}/handleft_test.nii.gz\"))\n",
    "dat = Brain_Data(files)\n",
    "dat.iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038645d5-cc5d-4acb-9f9f-504de6e123f8",
   "metadata": {},
   "source": [
    "# SecondLevel GLM analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2d620-0cc0-42f6-9fef-02248702da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nilearn\n",
    "from nilearn.image import load_img\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff45a6c8-242a-403f-a56f-78f51448e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stat_maps(data, prefix, save_loc='stat-maps'):\n",
    "    keys_of_interest = [\"z_score\", \"stat\", \"effect_size\"]\n",
    "    \n",
    "    if not os.path.exists(save_loc):\n",
    "        os.makedirs(save_loc)\n",
    "    \n",
    "    for i, key in enumerate(keys_of_interest):\n",
    "        path2save = os.path.join(save_loc, f\"{prefix}_{key}.nii.gz\")\n",
    "        nib.save(data[key], path2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869feb8-e91f-4211-8a7b-6f66082e6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the 2nd-level contrast matrix\n",
    "from nilearn.plotting import plot_design_matrix, plot_contrast_matrix\n",
    "n_subs = 20\n",
    "n = len(test_img_files)\n",
    "design_matrix = {}\n",
    "\n",
    "for label in range(len(class_labels)):\n",
    "    regressor = np.repeat(np.eye(len(class_labels))[label], n_subs)\n",
    "    design_matrix[f'{class_labels[label]}'] = regressor\n",
    "\n",
    "\"\"\"\n",
    "design_matrix['lh_vs_rh'] = np.repeat([0, 0, 1, -1, 0], n_subs)\n",
    "design_matrix['lf_vs_rf'] = np.repeat([1, -1, 0, 0, 0], n_subs)\n",
    "design_matrix['t_vs_all'] = np.repeat([-.25, -.25, -.25, -.25, 1], n_subs)\n",
    "design_matrix['f_vs_h'] = np.repeat([.5, .5, -.5, -.5, 0], n_subs)\n",
    "\"\"\"\n",
    "design_matrix['average'] = np.ones(n)\n",
    "\n",
    "for sub in range(n_subs):\n",
    "    regressor = np.tile(np.eye(n_subs)[sub], len(class_labels))\n",
    "    design_matrix[f'sub-{sub:02d}'] = regressor\n",
    "\n",
    "df_design_matrix = pd.DataFrame(design_matrix)\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "plot_design_matrix(df_design_matrix, rescale=False, ax=ax);\n",
    "ax.set_xticklabels(df_design_matrix.columns, fontsize=15, rotation=90, ha=\"center\");\n",
    "ax.set_yticklabels([0, 20, 40, 60, 80], fontsize=15);\n",
    "ax.set_ylabel(\"scan number\", fontsize=15);\n",
    "ax.xaxis.set_label_position('top') \n",
    "ax.set_title(\"2nd-level contrasts\", fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0e240-af56-47c3-90bd-a8b75a2713f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the real images\n",
    "test_img_files = []\n",
    "[test_img_files.extend(sorted(glob(f\"../copes/test/{class_labels[i]}/*.nii.gz\"))) for i in range(len(class_labels))]\n",
    "images = load_img(test_img_files)\n",
    "real = np.repeat([0,1,2,3,4], 20)\n",
    "\n",
    "mask = load_img(mni_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69c971-2440-4572-b80b-38da9efe6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the GLM once on the original beta maps\n",
    "glm_orig = SecondLevelModel(smoothing_fwhm=None, mask_img=mask)\n",
    "glm_orig.fit([nilearn.image.index_img(images, i) for i in range(n)], design_matrix=df_design_matrix)\n",
    "\n",
    "contrasts = [\"footleft\", \"footright\", \"handleft\", \"handright\", \"tongue\", \"average\"]\n",
    "\n",
    "for c, contrast in enumerate(contrasts):\n",
    "    maps_orig = glm_orig.compute_contrast(contrast, output_type=\"all\")\n",
    "    save_stat_maps(maps_orig, f\"orig-{contrast}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fad1a-7624-443d-8885-0b5206e15da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the GLM on the relevance maps for each individual fold\n",
    "# load the relevance images\n",
    "contrasts = [\"footleft\", \"footright\", \"handleft\", \"handright\", \"tongue\", \"average\"]\n",
    "save_loc = \"stat-maps/lrp\"\n",
    "\n",
    "for fold in range(10):\n",
    "    relevance_files = sorted(glob(f\"lrp/epsgamma_fold-{fold:02d}/*_test.nii.gz\"))\n",
    "    relevance_maps = load_img(relevance_files)\n",
    "    \n",
    "    # set up the GLM for the current fold\n",
    "    glm_lrp = SecondLevelModel(smoothing_fwhm=None, mask_img=mask)\n",
    "    glm_lrp.fit([nilearn.image.index_img(relevance_maps , i) for i in range(n)], design_matrix=df_design_matrix)\n",
    "    \n",
    "    for c, contrast in enumerate(contrasts):\n",
    "        maps_lrp = glm_lrp.compute_contrast(contrast, output_type=\"all\")\n",
    "        save_stat_maps(maps_lrp, f\"fold{fold:02d}-{contrast}\", save_loc=\"stat-maps/lrp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d29e5-f53b-4c9e-a81f-633a04f23aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts = [\"footleft\", \"footright\", \"handleft\", \"handright\", \"tongue\", \"average\"]\n",
    "#\"lh_vs_rh\", \"lf_vs_rf\", \"t_vs_all\", \"f_vs_h\"]\n",
    "\n",
    "for c, contrast in enumerate(contrasts):\n",
    "    maps_orig = glm_orig.compute_contrast(contrast, output_type=\"all\")\n",
    "    save_stat_maps(maps_orig, f\"orig-{contrast}\")\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(1,2,figsize=(18,6))\n",
    "    nilearn.plotting.plot_glass_brain(maps_orig['z_score'], colorbar=True, plot_abs=False, axes=axes[0]);\n",
    "    axes[0].set_title(f\"{contrast}-orig\")\n",
    "    nilearn.plotting.plot_glass_brain(maps_lrp['z_score'], colorbar=True, plot_abs=False, axes=axes[1]);\n",
    "    axes[1].set_title(f\"{contrast}-lrp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1a96d-bffa-4c9c-9252-62d500de5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(glob(f\"stat-maps/lrp-fold-{fold:02d}-*_z_score.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e397b-cbfc-4ee0-8e2a-970615c3f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(glob(f\"stat-maps/lrp-fold-{fold:02d}-*_z_score.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de56c5-88fe-4fea-8e28-12a867ddc68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltools.data import Brain_Data\n",
    "test = Brain_Data(sorted(glob(f\"stat-maps/lrp-fold-{fold:02d}-*_z_score.nii.gz\")), mask=mask)\n",
    "test.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabbe4ad-0038-4495-96f9-e76b2d961ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Brain_Data(sorted(glob(\"stat-maps/orig-*_z_score.nii.gz\")), mask=mask)\n",
    "test.iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810f293-3d70-4cc4-aead-056f505036da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SANITY CHECKS FOR RELEVANCE/XAI\n",
    "### OCCLUSION (faithfulness test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe0ee9-d5da-4246-b34d-3f56c7899a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delphi.utils.tools import occlude_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936b2ea-90e7-4f45-8ee4-8adb8e7a1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = np.concatenate([\n",
    "    np.arange(0, 2, .2),\n",
    "    np.arange(2, 5, .5),\n",
    "    np.arange(5, 10, 1),\n",
    "    np.arange(10, 32, 2)\n",
    "])\n",
    "accs = np.zeros((8, len(percentages)))\n",
    "n_voxel = np.zeros_like(percentages)\n",
    "\n",
    "\n",
    "for fold in range(2):\n",
    "    # load the trained network\n",
    "    model = BrainStateClassifier3d(f\"models/CV-motor/motor-classifier_fold-{fold:02d}\")\n",
    "    model.eval()\n",
    "    model.to(torch.device(\"cpu\"));\n",
    "    \n",
    "    relevance_files = sorted(glob(f\"lrp/epsgamma_fold-{fold:02d}/*nii.gz\"))\n",
    "    relevance_maps = load_img(relevance_files)\n",
    "\n",
    "    for i, frac in enumerate(percentages):\n",
    "        print(fold, i)\n",
    "        occluded = occlude_images(images, relevance_maps, mask, fraction=frac, get_fdata=True)\n",
    "        occluded = np.moveaxis(occluded, -1, 0)\n",
    "        occluded = torch.tensor(occluded).unsqueeze(1)\n",
    "        pred = np.argmax(model(occluded.float()).detach().cpu().numpy(), axis=1)\n",
    "        accs[fold, i] = compute_accuracy(real, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fe1b3-d9e9-4159-b746-4107ddf8461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = accs[:7].mean(axis=0)\n",
    "sd_acc = accs[:7].std(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "ax.errorbar(np.log(percentages), mean_acc, yerr=sd_acc, marker=\"o\", linewidth=3, capsize=5, capthick=2);\n",
    "ax.scatter(np.repeat(np.log(percentages), 7), accs[:7].transpose(), marker=\"o\", alpha=.2, color=\"black\");\n",
    "ax.set_xticks(np.log(percentages)), ax.set_xticklabels(percentages)\n",
    "ax.hlines(.2, ax.get_xlim()[0], ax.get_xlim()[1], color=\"black\", linestyle=\"--\")\n",
    "ax.set_title('Occlusion effect'), ax.set_xlabel('Percent occlusion'), ax.set_ylabel('accuracy')\n",
    "ax.spines['top'].set_visible(False), ax.spines['right'].set_visible(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874b2f8-ca45-436d-a361-ed65e29d4e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
