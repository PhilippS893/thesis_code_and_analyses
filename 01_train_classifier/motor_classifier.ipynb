{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199f3688-c4a4-4652-865c-740ab265e6aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train and evaluate a 3D Convolutional Neural Network (3dCNN) to classify motor tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512daf9-457e-4fb1-8f7d-b02a17edddca",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>In this notebook we create and train a 3D-Convolutional Neural Network which learns to classify different patterns of whole-brain fMRI statistical parameters (t-scores). In this first approach our goal is to train a classifier that can reliably distinguish between such whole-brain patterns for five limb movements (i.e., left/right hand, left/right foot, and tongue).\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed4397e-7b43-4598-9e27-a6f09fdc2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d87eac6-0be1-4c62-b097-753fc82f131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os, wandb, torch, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from delphi import mni_template\n",
    "from delphi.networks.ConvNets import BrainStateClassifier3d\n",
    "from delphi.utils.datasets import NiftiDataset\n",
    "from delphi.utils.tools import ToTensor, compute_accuracy, convert_wandb_config, read_config, z_transform_volume\n",
    "from delphi.utils.plots import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# you can find all these files in ../utils\n",
    "from utils.tools import attribute_with_method, concat_stat_files, compute_mi\n",
    "from utils.wandb_funcs import reset_wandb_env, wandb_plots\n",
    "from utils.random import set_random_seed\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b2335-28be-41c8-addf-9b9788f39cb2",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>To make sure that we obtain (almost) the same results for each execution we set the random seed of multiple different librabries (i.e., torch, random, numpy)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5ca42e-df0c-46ef-a1cf-771b1fa3d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = set_random_seed(2020) # the project started in the year 2020, hence the seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df7fee-a2ef-47fc-a91f-b28d6670b434",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73ca8fb-a9c1-424a-beeb-c91ddfd1b0be",
   "metadata": {},
   "source": [
    "In this section, we define and initialize our required variables. We first need to define which classes we want to predict, i.e., the conditions of the motor mapper. We then define a PyTorch dataset; in this case `NiftiDataset` is a custom written Dataset-Class (see https://github.com/PhilippS893/delphi). As is common practice in machine learning projects, we split our data into a training and validation dataset (ratio=80 to 20, respectively).\n",
    "\n",
    "Note: In case it is necessary to create a null-model, i.e., a neural network that is trained on data where the labels are randomized, one can set the parameter `shuffe_labels=False` to `True`. This is usually done to have a baseline for the null hypothesis that \"everything is random\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acec5605-27f4-452f-88d1-07a0f54d69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_LABEL = \"motor\"\n",
    "class_labels = sorted([\"handleft\", \"handright\", \"footleft\", \"footright\", \"tongue\"])\n",
    "\n",
    "data_test = NiftiDataset(\"../t-maps/test\", class_labels, 0, device=DEVICE, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34364974-90ec-4926-b384-297fd4b0a1b5",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>We now set some parameters required by w&b to properly store information about our trained neural networks.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c0b297-b18d-4e6d-b965-8f32551c649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the wandb sweep config\n",
    "# os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_ENTITY'] = \"philis893\" # this is my wandb account name. This can also be a group name, for example\n",
    "os.environ['WANDB_PROJECT'] = \"thesis\" # this is simply the project name where we want to store the sweep logs and plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69bd8c8-3f32-4293-8cb9-8ef47b87d297",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training the neural network(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8371a07-a271-4b50-8812-5e6c26673735",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>In this first approach, we estimated what parameters we could use for our 3d-CNN from existing literature. We make use of some functionality, e.g., the function \"read_config\", I wrote for the \"delphi\" toolbox (see https://github.com/PhilippS893/delphi). This function can read .yaml files with the formatting as below:</p>\n",
    "\n",
    "The contents of `hyperparameter.yaml`: <br>\n",
    "`kernel_size: 7`<br>\n",
    "`batch_size: 4`<br>\n",
    "`dropout: .5`<br>\n",
    "`learning_rate: 0.00001`<br>\n",
    "`epochs: 60`<br>\n",
    "`channels: [1, 8, 16, 32, 64]`<br>\n",
    "`lin_neurons: [128, 64]`<br>\n",
    "`pooling_kernel: 2`<br>\n",
    "\n",
    "The function `read_config` will return a dictionary variable containing all keyword-value pairs as set in the `hyperparameter.yaml`. We do this, because the `delphi` toolbox was written with dictionaries as configuration variables in mind and because we can easily submit dictionaries to `w&b` to keep track of such parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b5777-3c39-47b0-9c5d-58cc31d75169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(run, fold, data_train, data_valid, data_test, hp, class_labels, shuffled_labels=False):\n",
    "    reset_wandb_env()\n",
    "    \n",
    "    job_name = \"CV-shuffled\" if shuffled_labels else \"CV-real\"\n",
    "    wandb_kwargs = {\n",
    "        \"entity\": os.environ['WANDB_ENTITY'],\n",
    "        \"project\": os.environ['WANDB_PROJECT'],\n",
    "        \"group\": \"first-steps\",\n",
    "        \"name\": f\"motor_fold-{fold:02d}\",\n",
    "        \"job_type\": job_name if num_folds > 1 else \"train\",\n",
    "    }\n",
    "    \n",
    "    save_name = os.path.join(\"models\", job_name, wandb_kwargs[\"name\"])\n",
    "    if os.path.exists(save_name):\n",
    "        return\n",
    "    \n",
    "    # we adjust the random seed here to ensure that each run of each fold has a unique seed!\n",
    "    g = set_random_seed(2020 + fold + run)\n",
    "    \n",
    "    # we now use the wandb context to track the training and evaluation process.\n",
    "    # all settings and changes will be reset at the beginning of the fold-loop. (see line 11)\n",
    "    with wandb.init(config=hp, **wandb_kwargs) as run:\n",
    "        \n",
    "        # please note that this conversion is unnecessary if not using w&b!\n",
    "        model_cfg = convert_wandb_config(run.config, BrainStateClassifier3d._REQUIRED_PARAMS)\n",
    "        \n",
    "        # setup a model with the parameters given in model_cfg\n",
    "        model = BrainStateClassifier3d(input_dims, len(class_labels), model_cfg)\n",
    "        model.to(DEVICE);\n",
    "        \n",
    "        model.config[\"class_labels\"] = class_labels\n",
    "        \n",
    "        dl_train = DataLoader(data_train, batch_size=run.config.batch_size, shuffle=True, generator=g)\n",
    "        dl_valid = DataLoader(data_valid, batch_size=run.config.batch_size, shuffle=True, generator=g)\n",
    "        dl_test = DataLoader(data_test, batch_size=run.config.batch_size, shuffle=False, generator=g)\n",
    "\n",
    "        best_loss, best_acc = 100, 0\n",
    "        loss_acc = []\n",
    "        train_stats, valid_stats = [], []\n",
    "\n",
    "        # loop for the above set number of epochs\n",
    "        for epoch in range(run.config.epochs):\n",
    "            _, _ = model.fit(dl_train, lr=run.config.learning_rate)\n",
    "\n",
    "            # for validating or testing set the network into evaluation mode such that layers like dropout are not active\n",
    "            with torch.no_grad():\n",
    "                tloss, tstats = model.fit(dl_train, train=False)\n",
    "                vloss, vstats = model.fit(dl_valid, train=False)\n",
    "\n",
    "            # the model.fit() method has 2 output parameters: loss, stats = model.fit()\n",
    "            # the first parameter is simply the loss for each sample\n",
    "            # the second parameter is a matrix of n_classes+2-by-n_samples\n",
    "            # the first n_classes columns are the output probabilities of the model per class\n",
    "            # the second to last column (i.e., [:, -2]) represents the real labels\n",
    "            # the last column (i.e., [:, -1]) represents the predicted labels\n",
    "            tacc = compute_accuracy(tstats[:, -2], tstats[:, -1])\n",
    "            vacc = compute_accuracy(vstats[:, -2], vstats[:, -1])\n",
    "\n",
    "            loss_acc.append(pd.DataFrame([[tloss, vloss, tacc, vacc]],\n",
    "                                         columns=[\"train_loss\", \"valid_loss\", \"train_acc\", \"valid_acc\"]))\n",
    "\n",
    "            train_stats.append(pd.DataFrame(tstats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]]))\n",
    "            train_stats[epoch][\"epoch\"] = epoch\n",
    "            valid_stats.append(pd.DataFrame(vstats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]]))\n",
    "            valid_stats[epoch][\"epoch\"] = epoch\n",
    "\n",
    "            wandb.log({\n",
    "                \"train_acc\": tacc, \"train_loss\": tloss,\n",
    "                \"valid_acc\": vacc, \"valid_loss\": vloss\n",
    "            }, step=epoch)\n",
    "\n",
    "            print('Epoch=%03d, train_loss=%2.3f, train_acc=%1.3f, valid_loss=%2.3f, valid_acc=%1.3f' % \n",
    "                 (epoch, tloss, tacc, vloss, vacc))\n",
    "\n",
    "            if (vacc >= best_acc) and (vloss <= best_loss):\n",
    "                # assign the new best values\n",
    "                best_acc, best_loss = vacc, vloss\n",
    "                wandb.run.summary[\"best_valid_accuracy\"] = best_acc\n",
    "                wandb.run.summary[\"best_valid_epoch\"] = epoch\n",
    "                # save the current best model\n",
    "                model.save(save_name)\n",
    "                # plot some graphs for the validation data\n",
    "                wandb_plots(vstats[:, -2], vstats[:, -1], vstats[:, :-2], class_labels, \"valid\")\n",
    "\n",
    "\n",
    "        # save the files\n",
    "        full_df = pd.concat(loss_acc)\n",
    "        full_df.to_csv(os.path.join(save_name, \"loss_acc_curves.csv\"), index=False)\n",
    "        full_df = pd.concat(train_stats)\n",
    "        full_df.to_csv(os.path.join(save_name, \"train_stats.csv\"), index=False)\n",
    "        full_df = pd.concat(valid_stats)\n",
    "        full_df.to_csv(os.path.join(save_name, \"valid_stats.csv\"), index=False)\n",
    "\n",
    "        # load the best performing model\n",
    "        model = BrainStateClassifier3d(save_name)\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "        # EVALUATE THE MODEL ON THE TEST DATA\n",
    "        with torch.no_grad():\n",
    "            testloss, teststats = model.fit(dl_test, train=False)\n",
    "            \n",
    "        testacc = compute_accuracy(teststats[:, -2], teststats[:, -1])\n",
    "        df_test = pd.DataFrame(teststats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]])\n",
    "        df_test.to_csv(os.path.join(save_name, \"test_stats.csv\"), index=False)\n",
    "        \n",
    "        wandb.run.summary[\"test_accuracy\"] = testacc\n",
    "\n",
    "        wandb.log({\"test_accuracy\": testacc, \"test_loss\": testloss})\n",
    "        wandb_plots(teststats[:, -2], teststats[:, -1], teststats[:, :-2], class_labels, \"test\")\n",
    "\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c595940-a263-4257-95be-38f895269e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = read_config(\"hyperparameter.yaml\")\n",
    "\n",
    "num_folds = 10 # we decided to run a 10-fold cross-validation scheme\n",
    "run = 0 # in case you decide to do multiple runs of the cross-validation scheme\n",
    "input_dims = (91, 109, 91) # these are the 3D input dimension of our whole-brain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40287c-57a6-43f3-a812-38b6ecea3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f88ea-db23-4fc6-a4a3-b59243f2a4fd",
   "metadata": {},
   "source": [
    "### Run cross-validation training using correct labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd352b-3993-4986-8d8c-425dda5ecae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will split the train dataset into a train (80%) and validation (20%) set.\n",
    "data_train_full = NiftiDataset(\"../t-maps/train\", class_labels, 0, device=DEVICE, \n",
    "                               transform=ToTensor(), shuffle_labels=False)\n",
    "\n",
    "# we want a stratified shuffled split\n",
    "sss = StratifiedShuffleSplit(n_splits=num_folds, test_size=0.2, random_state=2020)\n",
    "\n",
    "for fold, (idx_train, idx_valid) in enumerate(sss.split(data_train_full.data, data_train_full.labels)):\n",
    "    data_train = torch.utils.data.Subset(data_train_full, idx_train)\n",
    "    data_valid = torch.utils.data.Subset(data_train_full, idx_valid)\n",
    "    train_network(run, fold, data_train, data_valid, data_test, hp, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e6f2f-8ae9-4b21-b11b-5085418d7f25",
   "metadata": {},
   "source": [
    "### Run cross-validation training using shuffled labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b378f-67ee-4936-a219-e3a419acb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will split the train dataset into a train (80%) and validation (20%) set.\n",
    "data_train_full = NiftiDataset(\"../t-maps/train\", class_labels, 20, device=DEVICE, \n",
    "                               transform=ToTensor(), shuffle_labels=True)\n",
    "\n",
    "# we want a stratified shuffled split\n",
    "sss = StratifiedShuffleSplit(n_splits=num_folds, test_size=0.2, random_state=2020)\n",
    "\n",
    "for fold, (idx_train, idx_valid) in enumerate(sss.split(data_train_full.data, data_train_full.labels)):\n",
    "    data_train = torch.utils.data.Subset(data_train_full, idx_train)\n",
    "    data_valid = torch.utils.data.Subset(data_train_full, idx_valid)\n",
    "    train_network(run, fold, data_train, data_valid, data_test, hp, class_labels, shuffled_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2236e-a9b5-41e9-b409-014fe5aa31b4",
   "metadata": {},
   "source": [
    "## Analyzing the network performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de90685-ac8e-4809-922d-fbd7306df991",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loss and accuracy curves for the real and shuffled labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01663ae8-ec96-411f-9241-d5c9ca59db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 18\n",
    "MEDIUM_SIZE = 22\n",
    "BIGGER_SIZE = 26\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c60806-7b28-43fe-96f2-af098ae17c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharex=True)\n",
    "label_order = [\"real\"]#, \"shuffled\"]\n",
    "n_folds = 7\n",
    "\n",
    "dfs = []\n",
    "for i, order in enumerate(label_order):\n",
    "    folds_real = sorted(glob(os.path.join(f\"models/CV-{n_folds}folds-{order}/*fold*\"))) \n",
    "    dfs.append(concat_stat_files(folds_real, \"loss_acc_curves.csv\"))\n",
    "    dfs[i][\"label_order\"] = order\n",
    "\n",
    "curves = pd.concat(dfs)\n",
    "curves[\"epoch\"] = curves.index\n",
    "\n",
    "sns.lineplot(ax=axes[0], data=curves.melt(value_vars=[\"train_loss\", \"valid_loss\"], id_vars=[\"epoch\", \"label_order\"], var_name=\"loss\", value_name=\"CrossEntropyLoss\"), \n",
    "             x=\"epoch\", y=\"CrossEntropyLoss\", hue=\"label_order\", style=\"loss\", markers=True, markersize=6,\n",
    "             linewidth=2, errorbar=(\"ci\", 95), n_boot=5000)\n",
    "sns.lineplot(ax=axes[1], data=curves.melt(value_vars=[\"train_acc\", \"valid_acc\"], id_vars=[\"epoch\", \"label_order\"], var_name=\"accuracy\", value_name=\"acc\"), \n",
    "             x=\"epoch\", y=\"acc\", hue=\"label_order\", style=\"accuracy\", markers=True, markersize=6,\n",
    "             linewidth=2, errorbar=(\"ci\", 95), n_boot=5000)\n",
    "\n",
    "for i in range(2):\n",
    "    axes[i].spines[[\"top\", \"right\"]].set_visible(False);\n",
    "    axes[i].legend(frameon=False, loc=\"center right\", fontsize=18)\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.savefig('figures/loss-acc-curves-across-folds.pdf', facecolor=fig.get_facecolor(), transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df93ceb-f554-412d-b48a-138bf39b3e0d",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>We can see from these lines, that the network with shuffled input-label mappings seems to begin learning to identify patterns in the shuffled data. => It overfits.\n",
    "    This is corroborated by the fact that the validation accuracy stays at chance level. However, because we see an increase only training classification in 60 epochs it is not save to say that it may not also increase for the validation set with longer training durations. Thus we opted to train the same architecture with shuffled input-label mappings for 500 epochs. You can see the results below:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba91d2-5894-4e63-87fc-d494fce99f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_500 = sorted(glob(os.path.join(f\"models/motor-shuffled-500epochs/*fold*\"))) \n",
    "curves_500 = concat_stat_files(folds_500, \"loss_acc_curves.csv\")\n",
    "curves_500[\"epoch\"] = curves_500.index\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharex=True)\n",
    "sns.lineplot(ax=axes[0], data=curves_500.melt(value_vars=[\"train_loss\", \"valid_loss\"], id_vars=[\"epoch\"], var_name=\"loss\", value_name=\"CrossEntropyLoss\"), \n",
    "             x=\"epoch\", y=\"CrossEntropyLoss\", hue=\"loss\", style=\"loss\", \n",
    "             linewidth=2, errorbar=(\"ci\", 95), n_boot=5000)\n",
    "sns.lineplot(ax=axes[1], data=curves_500.melt(value_vars=[\"train_acc\", \"valid_acc\"], id_vars=[\"epoch\"], var_name=\"accuracy\", value_name=\"acc\"), \n",
    "             x=\"epoch\", y=\"acc\", hue=\"accuracy\", style=\"accuracy\", \n",
    "             linewidth=2, errorbar=(\"ci\", 95), n_boot=5000)\n",
    "\n",
    "for i in range(2):\n",
    "    axes[i].spines[[\"top\", \"right\"]].set_visible(False);\n",
    "    axes[i].legend(frameon=False, loc=\"center right\", fontsize=18)\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('figures/loss-acc-curves-across-folds-shuffled500.pdf', facecolor=fig.get_facecolor(), transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016a9b7d-b8df-4d2b-a94c-293d2251b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the test classification accuracy of the folds\n",
    "label_condition = [\"real\", \"shuffled\"]\n",
    "stat_mats = {\n",
    "    \"real\": [],\n",
    "    \"shuffled\": [],\n",
    "}\n",
    "\n",
    "test_loader = DataLoader(data_test, batch_size=4, shuffle=False)\n",
    "\n",
    "accs = np.zeros((10, 2))\n",
    "\n",
    "for i, c in enumerate(label_condition):\n",
    "    \n",
    "    # get the folds\n",
    "    folds = sorted(glob(os.path.join(f\"models/CV-{c}\", \"*fold*\")))\n",
    "    \n",
    "    for j, fold in enumerate(folds):\n",
    "        \n",
    "        if not os.path.isfile(os.path.join(fold, \"test_stats.csv\")):\n",
    "            model = BrainStateClassifier3d(fold)\n",
    "            model.to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _ , stats = model.fit(test_loader, train=False)\n",
    "\n",
    "            df_test = pd.DataFrame(stats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]])\n",
    "            df_test.to_csv(os.path.join(fold, \"test_stats.csv\"), index=False)\n",
    "            stat_mats[c].append(df_test)\n",
    "            accs[j, i] = compute_accuracy(stats[:, -2], stats[:, -1])\n",
    "        else:\n",
    "            stat_mats[c].append(pd.read_csv(os.path.join(fold, \"test_stats.csv\")))\n",
    "            accs[j, i] = compute_accuracy(stat_mats[c][j][\"real\"], stat_mats[c][j][\"predicted\"])\n",
    "        \n",
    "\n",
    "df_accs = pd.DataFrame(accs.tolist(), columns=label_condition)\n",
    "df_accs.to_csv(\"stats/motor-accs.csv\", index=False)\n",
    "\n",
    "df_acc_transformed = np.arcsin(df_accs)\n",
    "df_acc_transformed.to_csv(\"stats/motor-accs-transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0895e3d6-ee7d-4d25-9240-ee2d32bf622b",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>The resulting graph of the code below consists of 3 panels. The panel on the left shows the average test classification performance across all folds for the 3D CNNs trained with real and shuffled input-label mappings. The blue and violet dots represent the individual test accuracies for a given fold. The dashed line at 0.2 represents the chance level. <br>\n",
    "We clearly see that the networks trained with real input-label mappings perform reliably above the chance level, whereas the networks trained with shuffled input-label mappings perform at chance level.\n",
    "<br><br>\n",
    "The other two panels show the confusion matrices for the real (left) and shuffled (right) input-label mappings. This is just another representation that the input-label mapping indeed matters for the network to learn to distinguish between the conditions of the motor mapper.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7041a9-0de3-447f-a4e8-80e23ad3cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(20,6), gridspec_kw={'width_ratios': [.5, 1, 1]})\n",
    "\n",
    "# plot the average test accuracy \n",
    "sns.barplot(ax=ax[0], data=df_accs, color=[.5,.5,.5], alpha=.2, errorbar=(\"ci\", 95), n_boot=5000, capsize=.1, width=.4)\n",
    "sns.stripplot(ax=ax[0], data=df_accs, zorder=1, alpha=.7, size=8, legend=False, palette=\"cool\")\n",
    "ax[0].axhline(0.2, linestyle=\"--\", color=\"black\", zorder=0, label=\"chance level\")\n",
    "ax[0].set(ylabel=\"accuracy\", xlabel=\"label order\", title=\"average classification performance\");\n",
    "ax[0].legend(frameon=False)\n",
    "ax[0].spines[[\"top\", \"right\"]].set_visible(False);\n",
    "\n",
    "# plot the confusion matrix across all folds for the \"real\" label order\n",
    "df = pd.concat(stat_mats[\"real\"])\n",
    "conf_mat, conf_ax = confusion_matrix(df[\"real\"], df[\"predicted\"], df.columns[:-2], normalize=False, ax=ax[1], **{\"vmin\": 0, \"vmax\": 200})\n",
    "ax[1].set_title(\"real label order\");\n",
    "\n",
    "# plot the confusion matrix across all folds for the \"shuffled\" label order\n",
    "df = pd.concat(stat_mats[\"shuffled\"])\n",
    "conf_mat, conf_ax = confusion_matrix(df[\"real\"], df[\"predicted\"], df.columns[:-2], normalize=False, ax=ax[2], **{\"vmin\": 0, \"vmax\": 200})\n",
    "ax[2].set_title(\"shuffled label order\");\n",
    "fig.colorbar(conf_ax, ax=ax[2], )\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('figures/test-performance-across-folds.pdf', facecolor=fig.get_facecolor(), transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f0bd8-c7d2-4bce-8466-3fb18dc9e612",
   "metadata": {},
   "source": [
    "## Investigate what information was deemed relevant (XAI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "134dbc4e-01bd-4e95-b639-c046d0dcca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import GuidedBackprop\n",
    "from zennit.rules import Epsilon, Gamma, Pass\n",
    "from zennit.types import Convolution, Linear, Activation\n",
    "from zennit.composites import LayerMapComposite\n",
    "from delphi.utils.tools import save_in_mni\n",
    "from utils.tools import attribute_with_method\n",
    "\n",
    "composite_lrp_map = [\n",
    "    (Activation, Pass()),\n",
    "    (Convolution, Gamma(gamma=.25)),\n",
    "    (Linear, Epsilon(epsilon=0)),\n",
    "]\n",
    "\n",
    "LRP = LayerMapComposite(\n",
    "    layer_map=composite_lrp_map,\n",
    ")\n",
    "LRP.__name__ = 'LRP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6266b243-b8bb-450b-87e0-2cbb3032043a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_order = \"shuffled\"\n",
    "\n",
    "n_folds = 7\n",
    "\n",
    "attributor_method = [LRP, GuidedBackprop]\n",
    "\n",
    "for i, method in enumerate(attributor_method):\n",
    "\n",
    "    method_name = str(method.__name__).lower()\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        # load the trained network\n",
    "        model = BrainStateClassifier3d(f\"models/CV-7folds-{label_order}/fold-{fold:02d}\")\n",
    "        model.to(torch.device(\"cpu\"));\n",
    "        model.eval()\n",
    "        \n",
    "        out_dir_name = f\"{method_name}/{label_order}/fold-{fold:02d}\"\n",
    "        if not os.path.exists(out_dir_name):\n",
    "            os.makedirs(out_dir_name)\n",
    "\n",
    "        for j in range(len(class_labels)):\n",
    "\n",
    "            print(f\"Running {method_name} on {class_labels[j]}\")\n",
    "\n",
    "            out_fname = os.path.join(out_dir_name, '%s.nii.gz' % class_labels[j])\n",
    "            if os.path.isfile(out_fname):\n",
    "                print(f\"{out_fname} already exists. Skipping\")\n",
    "                continue\n",
    "\n",
    "            dl = DataLoader(\n",
    "                NiftiDataset('../t-maps/test', [class_labels[j]], 0, device=torch.device(\"cpu\"), transform=ToTensor()),\n",
    "                batch_size=20, shuffle=False, num_workers=0\n",
    "            )\n",
    "\n",
    "            for i, (volume, target) in enumerate(dl):\n",
    "\n",
    "                attribution = attribute_with_method(method, model, volume, target)\n",
    "\n",
    "                subject_attr = np.moveaxis(attribution.squeeze().detach().numpy(), 0, -1)\n",
    "                subject_attr = z_transform_volume(subject_attr)\n",
    "                avg_attr = subject_attr.mean(axis=-1)\n",
    "\n",
    "            save_in_mni(subject_attr, out_fname)\n",
    "\n",
    "            avg_out_name = os.path.join(out_dir_name, \"avg\")\n",
    "            if not os.path.exists(avg_out_name):\n",
    "                os.makedirs(avg_out_name)\n",
    "            save_in_mni(avg_attr, os.path.join(avg_out_name, '%s.nii.gz' % class_labels[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b843b7-2370-4e21-bd69-a744286fea57",
   "metadata": {},
   "source": [
    "Another sanity check for attribution methods put forth by Adebayo and colleagues is to test the similarity between attribution maps of trained networks with those of randomly initialized weights.\n",
    "If they were to be similar, we can say that the attribution map is insensitive to the model parameters, which would reduce confidence in the attribution maps of trained networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2206fad-8af2-4e09-9ee9-c50067eb9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 1\n",
    "\n",
    "attributor_method = [LRP, GuidedBackprop]\n",
    "\n",
    "model_config = read_config(\"hyperparameter.yaml\")\n",
    "\n",
    "seed = 1337\n",
    "ctr = 0\n",
    "\n",
    "for i, method in enumerate(attributor_method):\n",
    "\n",
    "    method_name = str(method.__name__).lower()\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "       \n",
    "        g = set_random_seed(seed + ctr)\n",
    "        \n",
    "        model = BrainStateClassifier3d((91, 109, 91), len(class_labels), model_config)\n",
    "        model.to(torch.device(\"cpu\"));\n",
    "        model.eval()\n",
    "        \n",
    "        out_dir_name = f\"{method_name}/model-random/{TASK_LABEL}_fold-{fold:02d}\"\n",
    "        if not os.path.exists(out_dir_name):\n",
    "            os.makedirs(out_dir_name)\n",
    "\n",
    "        for j in range(len(class_labels)):\n",
    "\n",
    "            print(f\"Running {method_name} on {class_labels[j]}\")\n",
    "\n",
    "            out_fname = os.path.join(out_dir_name, '%s.nii.gz' % class_labels[j])\n",
    "            if os.path.isfile(out_fname):\n",
    "                print(f\"{out_fname} already exists. Skipping\")\n",
    "                continue\n",
    "\n",
    "            dl = DataLoader(\n",
    "                NiftiDataset('../t-maps/test', [class_labels[j]], 0, device=torch.device(\"cpu\"), transform=ToTensor()),\n",
    "                batch_size=20, shuffle=False, num_workers=0\n",
    "            )\n",
    "\n",
    "            for i, (volume, target) in enumerate(dl):\n",
    "\n",
    "                attribution = attribute_with_method(method, model, volume, target)\n",
    "\n",
    "                subject_attr = np.moveaxis(attribution.squeeze().detach().numpy(), 0, -1)\n",
    "                subject_attr = z_transform_volume(subject_attr)\n",
    "                avg_attr = subject_attr.mean(axis=-1)\n",
    "\n",
    "            save_in_mni(subject_attr, out_fname)\n",
    "\n",
    "            avg_out_name = os.path.join(out_dir_name, \"avg\")\n",
    "            if not os.path.exists(avg_out_name):\n",
    "                os.makedirs(avg_out_name)\n",
    "            save_in_mni(avg_attr, os.path.join(avg_out_name, '%s.nii.gz' % class_labels[j]))\n",
    "            \n",
    "        ctr+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a2345-1cf1-4712-970e-c5877fb8ac66",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Identify the best fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8e74a-0601-4456-829c-44c3f668f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.wandb_funcs import get_wandb_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936f4317-ee39-47b1-bfa4-1856fcbb70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_of_interest = ['group', 'job_type', 'run_name', 'test_accuracy', 'train_acc', 'valid_acc', \n",
    "                    'valid_loss', 'best_valid_epoch', 'best_valid_accuracy', 'test_loss', 'train_loss']\n",
    "wandb_df = get_wandb_csv(\"philis893\", \"thesis\", \"first-steps-motor\", keys_of_interest, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9a6630-4f32-47ec-a520-2540f801539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_runs = wandb_df[wandb_df.job_type == \"CV-7folds\"]\n",
    "# sort according to best_valid_accuracy (desc), test_accuracy (desc), and test_loss (asc). Take the first entry => best fold\n",
    "real_runs_sorted = real_runs.sort_values([\"best_valid_accuracy\", \"test_accuracy\", \"test_loss\"], ascending=[False, False, True])\n",
    "real_runs_sorted.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db1374d-0ada-4364-9366-ce0afd81d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_FOLD = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038645d5-cc5d-4acb-9f9f-504de6e123f8",
   "metadata": {},
   "source": [
    "# SecondLevel GLM analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d8075d-c6fb-424f-bb54-9ece453aa3a3",
   "metadata": {},
   "source": [
    "We need some way to compare the attribution maps from LRP and GBP to the original t-maps. To do this, we first compute a group level analysis across the subjects in the left-out test dataset.\n",
    "That is, we compute a group level \n",
    "* t-map, \n",
    "* LRP-map, and \n",
    "* GBP-map.\n",
    "\n",
    "In a later stage we can then use, for example, mutual information to quantify the similarity in a whithin subject and subject-vs-grpmap fashion. \n",
    "With such comparisons we can check whether mutual information of LRP/GBP maps with their respective group map is larger than, e.g., the mutual information between single subjects' t-maps (i.e., the original input data) with their respective group map.\n",
    "\n",
    "We therefore will perform the following comparisons:\n",
    "\n",
    "* subattr vs grpattr (grp attr is a map computed by leaving the subject out of the GLM whos map we want to compare to the grp, e.g., leave-out subject-01 in computing the grp map but use its attribution map to compute mutual information)\n",
    "* subt vs grpt (same as above)\n",
    "* subattr vs subt\n",
    "* grpattr vs grpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2d620-0cc0-42f6-9fef-02248702da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nilearn\n",
    "from nilearn.image import load_img\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "import nibabel as nib\n",
    "\n",
    "def save_stat_maps(data, prefix, save_loc='stat-maps', maps_of_interest=[\"z_score\"]):\n",
    "    \n",
    "    if not os.path.exists(save_loc):\n",
    "        os.makedirs(save_loc)\n",
    "    \n",
    "    for i, key in enumerate(maps_of_interest):\n",
    "        path2save = os.path.join(save_loc, f\"{prefix}_{key}.nii.gz\")\n",
    "        nib.save(data[key], path2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0e240-af56-47c3-90bd-a8b75a2713f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the real images\n",
    "test_img_files = []\n",
    "[test_img_files.extend(sorted(glob(f\"../copes/test/{class_labels[i]}/*.nii.gz\"))) for i in range(len(class_labels))]\n",
    "images = load_img(test_img_files)\n",
    "\n",
    "# assign the correct labels to each file\n",
    "real = np.repeat([0,1,2,3,4], 20)\n",
    "\n",
    "# a whole brain mask\n",
    "mask = load_img(mni_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a12b7-77e8-4ab0-821a-87c1bb9fbc1c",
   "metadata": {},
   "source": [
    "In this group level analysis we are interested in computing the average t-map for each condition: footleft, footright, handleft, handright, and tongue. \n",
    "Just due to curiousity we will also compute an average t-map across all conditions.\n",
    "\n",
    "The code cell below produces and plots the design matrix for our GLM analysis.\n",
    "\n",
    "The data and matrix are setup in a way that the all files of the same condition are grouped together, hence we can see 20 '1's for each condition (first 5 columns). The \"average\" contrast simply contains \"1\"s for all input volumes.\n",
    "As this is a paired design we need to assign the subjects to their respective volumes. You can see this by the sub-XX columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869feb8-e91f-4211-8a7b-6f66082e6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the 2nd-level contrast matrix\n",
    "from nilearn.plotting import plot_design_matrix, plot_contrast_matrix\n",
    "n_subs = 20\n",
    "n = len(test_img_files)\n",
    "design_matrix = {}\n",
    "\n",
    "for label in range(len(class_labels)):\n",
    "    regressor = np.repeat(np.eye(len(class_labels))[label], n_subs)\n",
    "    design_matrix[f'{class_labels[label]}'] = regressor\n",
    "\n",
    "\"\"\" In case we would want some extra contrasts\n",
    "design_matrix['lf_vs_all'] = np.repeat([1, -.25, -.25, -.25, -.25], n_subs)\n",
    "design_matrix['rf_vs_all'] = np.repeat([-.25, 1, -.25, -.25, -.25], n_subs)\n",
    "design_matrix['lh_vs_all'] = np.repeat([-.25, -.25, 1, -.25, -.25], n_subs)\n",
    "design_matrix['rh_vs_all'] = np.repeat([-.25, -.25, -.25, 1, -.25], n_subs)\n",
    "design_matrix['t_vs_all'] = np.repeat([-.25, -.25, -.25, -.25, 1], n_subs)\n",
    "\"\"\"\n",
    "\n",
    "design_matrix['average'] = np.ones(n) # the average across al conditions simply takes all files as input\n",
    "\n",
    "for sub in range(n_subs):\n",
    "    regressor = np.tile(np.eye(n_subs)[sub], len(class_labels))\n",
    "    design_matrix[f'sub-{sub:02d}'] = regressor\n",
    "\n",
    "df_design_matrix = pd.DataFrame(design_matrix)\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "plot_design_matrix(df_design_matrix, rescale=False, ax=ax);\n",
    "ax.set_xticklabels(df_design_matrix.columns, fontsize=15, rotation=90, ha=\"center\");\n",
    "ax.set_yticks([0, 20, 40, 60, 80])\n",
    "ax.set_yticklabels([0, 20, 40, 60, 80], fontsize=15);\n",
    "ax.set_ylabel(\"sample\", fontsize=15);\n",
    "ax.xaxis.set_label_position('top') \n",
    "ax.set_title(\"2nd-level contrasts\", fontsize=20);\n",
    "\n",
    "plt.savefig('figures/2nd-level-matrix-nilearn.pdf', facecolor=fig.get_facecolor(), transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8890f3-4510-43bb-a212-a0b8c9824ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the glm\n",
    "glm = SecondLevelModel(smoothing_fwhm=None, mask_img=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69c971-2440-4572-b80b-38da9efe6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the GLM once on the original beta maps\n",
    "glm.fit([nilearn.image.index_img(images, i) for i in range(n)], design_matrix=df_design_matrix)\n",
    "\n",
    "contrasts = [\"footleft\", \"footright\", \"handleft\", \"handright\", \"tongue\", \"average\"]\n",
    "#contrasts = ['footleft', 'footright', 'handleft', 'handright', 'tongue', 'lf_vs_all', 'rf_vs_all', 'lh_vs_all', 'rh_vs_all', 't_vs_all', 'average']\n",
    "\n",
    "for c, contrast in enumerate(contrasts):\n",
    "    maps_orig = glm.compute_contrast(contrast, output_type=\"all\")\n",
    "    save_stat_maps(maps_orig, f\"{contrast}\", save_loc=\"stat-maps/orig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fad1a-7624-443d-8885-0b5206e15da0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform the GLM on the relevance maps for each individual fold\n",
    "# load the relevance images\n",
    "contrasts = [\"footleft\", \"footright\", \"handleft\", \"handright\", \"tongue\", \"average\"]\n",
    "attr_types = [\"lrp\", \"guidedbackprop\"] #\"lrp\" \"guidedbackprop\"\n",
    "label_order = \"shuffled\" #, \"shuffled\"\n",
    "\n",
    "overwrite = True\n",
    "\n",
    "n_folds = 7\n",
    "\n",
    "for a, attr_type in enumerate(attr_types):\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "\n",
    "        print(attr_type, label_order, fold)\n",
    "\n",
    "        save_loc = os.path.join(\"stat-maps\", attr_type, label_order, f\"motor_fold-{fold:02d}\")\n",
    "\n",
    "        if not os.path.isdir(save_loc) or overwrite:\n",
    "\n",
    "            relevance_files = glob(os.path.join(attr_type, label_order, f\"fold-{fold:02d}/*.nii.gz\"))\n",
    "            relevance_maps = load_img(relevance_files)\n",
    "\n",
    "            # set up the GLM for the current fold\n",
    "            glm.fit([nilearn.image.index_img(relevance_maps , i) for i in range(n)], design_matrix=df_design_matrix)\n",
    "\n",
    "            for c, contrast in enumerate(contrasts):\n",
    "                maps_attr = glm.compute_contrast(contrast, output_type=\"all\")\n",
    "                save_stat_maps(maps_attr, f\"{contrast}\", save_loc=save_loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c870f8-f3d3-4c08-9513-b96c434321d3",
   "metadata": {},
   "source": [
    "### Leave-one-subject-out grp maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a3857-fef6-47bc-a47a-1763e0e05c9c",
   "metadata": {},
   "source": [
    "Now that we have the group LRP, GBP, and t-maps, we can turn to the leave-one-subject-out tests. We need these group statistics as well to be unbiased in computing the sub(attr/t) vs group(attr/t) mutual information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b451f5-5e1c-44da-9722-299dbeee7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a GLM for the test data set by leaving 1-subject out. We will need this for the mutual information analysis later\n",
    "contrasts = [\"footleft\", \"footright\", \"handleft\", \"handright\", \"tongue\", \"average\"]\n",
    "\n",
    "sub_list = np.tile(np.arange(n_subs), 5)\n",
    "\n",
    "for s in tqdm(range(n_subs)):\n",
    "    \n",
    "    # copy the original design matrix\n",
    "    this_dm = df_design_matrix.copy()\n",
    "    \n",
    "    # now drop the respective subject\n",
    "    this_dm = this_dm.drop(labels=np.squeeze(np.where(sub_list == s)), axis=\"index\")\n",
    "    this_dm = this_dm.drop(columns=[f\"sub-{s:02d}\"])\n",
    "    #plot_design_matrix(this_dm)\n",
    "    \n",
    "    idcs = np.arange(n)\n",
    "    idcs = np.delete(idcs, np.where(sub_list == s))\n",
    "    \n",
    "    # perform the GLM on the all subs except s\n",
    "    glm.fit([nilearn.image.index_img(images, i) for i in idcs], design_matrix=this_dm)\n",
    "\n",
    "    for c, contrast in enumerate(contrasts):\n",
    "        maps_orig = glm.compute_contrast(contrast, output_type=\"all\")\n",
    "        save_stat_maps(maps_orig, f\"{contrast}_wo-sub{s:02d}\", save_loc=\"stat-maps/orig/left-out\", maps_of_interest=[\"z_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83478a37-b850-4550-8ea4-7b77eb0c9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE THE GLM FOR EACH FOLD BUT LEAVE OUT ONE SUBJECT AT A TIME\n",
    "# perform the GLM on the relevance maps for each individual fold\n",
    "# load the relevance images\n",
    "contrasts = [\"footleft\", \"footright\", \"handleft\", \"handright\", \"tongue\", \"average\"]\n",
    "\n",
    "attr_types = [\"lrp\", \"guidedbackprop\"] #\"lrp\" \"guidedbackprop\"\n",
    "\n",
    "label_orders = \"real\" #, \"shuffled\"\n",
    "\n",
    "overwrite = False\n",
    "\n",
    "n_folds = 7\n",
    "\n",
    "sub_list = np.tile(np.arange(n_subs), 5)\n",
    "\n",
    "for a, attr_type in enumerate(attr_types):\n",
    "        \n",
    "    print(attr_type, label_order)\n",
    "        \n",
    "    for fold in tqdm(range(n_folds), desc=\"folds\"):\n",
    "\n",
    "        save_loc = os.path.join(\"stat-maps\", attr_type, label_order, f\"motor_fold-{fold:02d}\", \"left-out\")\n",
    "\n",
    "        if not os.path.isdir(save_loc) or overwrite:\n",
    "            \n",
    "            # load the files for a given fold\n",
    "            relevance_files = glob(os.path.join(attr_type, label_order, f\"fold-{fold:02d}/*.nii.gz\"))\n",
    "            relevance_maps = load_img(relevance_files)\n",
    "\n",
    "            for s in tqdm(range(n_subs), leave=False, desc=\"subs\"):\n",
    "\n",
    "                # copy the original design matrix\n",
    "                this_dm = df_design_matrix.copy()\n",
    "\n",
    "                # now drop subject s from the design matrix\n",
    "                this_dm = this_dm.drop(labels=np.squeeze(np.where(sub_list == s)), axis=\"index\")\n",
    "                this_dm = this_dm.drop(columns=[f\"sub-{s:02d}\"])\n",
    "\n",
    "                # remove the subject s' indices from the data list\n",
    "                idcs = np.arange(n)\n",
    "                idcs = np.delete(idcs, np.where(sub_list == s))\n",
    "                \n",
    "                # perform the GLM on the all subs except s\n",
    "                glm.fit([nilearn.image.index_img(relevance_maps, i) for i in idcs], design_matrix=this_dm)\n",
    "\n",
    "                for c, contrast in enumerate(contrasts):\n",
    "                    maps_orig = glm.compute_contrast(contrast, output_type=\"all\")\n",
    "                    save_stat_maps(maps_orig, f\"{contrast}_wo-sub{s:02d}\", save_loc=save_loc, maps_of_interest=[\"z_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810f293-3d70-4cc4-aead-056f505036da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SANITY CHECKS FOR RELEVANCE/XAI\n",
    "### OCCLUSION (faithfulness test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe0ee9-d5da-4246-b34d-3f56c7899a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delphi.utils.tools import occlude_images\n",
    "from delphi.utils.tools import occlude_images\n",
    "from utils.tools import run_pca, run_svm, predict\n",
    "import pickle as pk\n",
    "from nilearn.masking import apply_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c222dd-e86f-4db5-a6bb-f4a9ab2513a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlude_images(images, attributions, mask, fraction=1, get_fdata=False) -> nib.Nifti1Image:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        images:\n",
    "        attributions:\n",
    "        mask:\n",
    "        fraction:   voxel percentage to occlude (default=1%)\n",
    "        get_fdata:  in case one wants to get the numpy arrays already.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    from nilearn.masking import apply_mask, unmask\n",
    "\n",
    "    fraction = fraction / 100\n",
    "\n",
    "    # mask the images such that we only really consider brain voxels\n",
    "    images_masked = apply_mask(images, mask)\n",
    "    attributions_masked = apply_mask(attributions, mask)\n",
    "\n",
    "    # find the indices of the largest n voxels for each attribution image (number depends on fraction)\n",
    "    if len(attributions_masked.shape) < 2:\n",
    "        occlusion_indices = np.argsort(a=attributions_masked)[::-1]  # this means we find the largest.\n",
    "        occlusion_indices = occlusion_indices[:int(fraction * occlusion_indices.shape[-1])]\n",
    "    else:\n",
    "        occlusion_indices = np.argsort(a=attributions_masked, axis=1)[:, ::-1]  # this means we find the largest.\n",
    "        occlusion_indices = occlusion_indices[:, :int(fraction * occlusion_indices.shape[-1])]\n",
    "\n",
    "    # dummy for occluded images\n",
    "    occluded_images = np.array(images_masked)\n",
    "    occluded_images[:, occlusion_indices] = 0\n",
    "\n",
    "    # convert the occluded_images back into 3d nibabel format\n",
    "    if not get_fdata:\n",
    "        return unmask(occluded_images, mask), occlusion_indices.shape[-1]\n",
    "    else:\n",
    "        return unmask(occluded_images, mask).get_fdata(), occlusion_indices.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f303df3-e775-4afb-aaf8-8dc2c19a0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"footleft\", \"footright\", \"handleft\", \"handright\", \"tongue\"]\n",
    "\n",
    "percentages = np.concatenate([\n",
    "    np.arange(0, 2, .2),\n",
    "    np.arange(2, 5, .5),\n",
    "    np.arange(5, 10, 1),\n",
    "    np.arange(10, 32, 2)\n",
    "])\n",
    "\n",
    "mask = mni_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e665b10-4337-45a2-a836-ce0a1b090b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for c, label in tqdm(enumerate(class_labels), leave=False, desc=\"class\"):\n",
    "    images.append(load_img(glob(f\"../t-maps/test/{label}/*.nii.gz\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6bddc3-51ce-4b66-a2aa-a655cb7a944d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the decision boundary maps (i.e., the weight maps of the SVM; we can consider those to be the \"explanation\" of the SVM)\n",
    "n_folds = 7\n",
    "df_svm = []\n",
    "real = np.repeat(np.arange(len(class_labels)), 20)\n",
    "\n",
    "for f in range(n_folds):\n",
    "    \n",
    "    svm_files = load_img(f\"../00_svm/svm_maps/nsubs-120/k-fold_motor_ss-0mm_fold{f:02d}_ovr_120subs_600dims_seed2020.nii.gz\")\n",
    "    pca_file = f\"../00_svm/pca_models/nsubs-120/k-fold_motor_ss-0mm_fold{f:02d}_600samples_seed{2020+f}.pkl\"\n",
    "    with open(pca_file, 'rb') as pickle_file:\n",
    "        pca = pk.load(pickle_file)\n",
    "\n",
    "    svm_file = f\"../00_svm/svm_models/nsubs-120/k-fold_motor_ss-0mm_fold{f:02d}_ovr_120subs_600dims_seed2020.pkl\"\n",
    "    with open(svm_file, 'rb') as pickle_file:\n",
    "        svm = pk.load(pickle_file)\n",
    "\n",
    "    accs = np.zeros(len(percentages))   \n",
    "\n",
    "    for i, frac in tqdm(enumerate(percentages), leave=False, desc=\"fractions\"):\n",
    "        occluded = []\n",
    "        for c, label in enumerate(class_labels):\n",
    "            # load the data\n",
    "            occu, _ = occlude_images(images[c], nilearn.image.index_img(svm_files , c), mask, fraction=frac, get_fdata=False)\n",
    "            occluded.append(occu)\n",
    "        occluded = nilearn.image.concat_imgs(occluded)\n",
    "        occluded = apply_mask(occluded, mni_template)\n",
    "        # transform the data\n",
    "        occluded = pca.transform(occluded)\n",
    "        _, accs[i] = predict(svm, occluded, real)\n",
    "        #print(accs[i])\n",
    "\n",
    "    df_svm.append(pd.DataFrame(accs.tolist(), columns=[\"accuracy\"]))\n",
    "    df_svm[f][\"algorithm\"] = \"svm\"\n",
    "    df_svm[f][\"prct_occluded\"] = percentages\n",
    "\n",
    "df_stacked = pd.concat(df_svm)\n",
    "df_stacked.to_csv(\"stats/svm_occlusion_curves.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4aad81-1369-4aad-bbc9-2f0a0b8f60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the t-scores for each subject\n",
    "test_img_files = []\n",
    "[test_img_files.extend(glob(f\"../t-maps/test/{class_labels[i]}/*.nii.gz\")) for i in range(len(class_labels))]\n",
    "images = load_img(test_img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936b2ea-90e7-4f45-8ee4-8adb8e7a1cce",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "xai_algo = [\"lrp\", \"guidedbackprop\"]\n",
    "#accs = np.zeros((10, len(percentages)))\n",
    "#n_voxel = np.zeros_like(percentages)\n",
    "\n",
    "df_occlu = []\n",
    "\n",
    "if not os.path.isfile(\"stats/occlusion_curves.csv\"):\n",
    "\n",
    "    for i, algo in enumerate(xai_algo):\n",
    "\n",
    "        folds = sorted(glob(os.path.join(algo, \"real\", \"*fold*\")))\n",
    "\n",
    "        for f, fold in enumerate(folds):\n",
    "            # load the trained network\n",
    "            model = BrainStateClassifier3d(f\"models/CV-7folds-real/fold-{f:02d}\")\n",
    "            model.eval()\n",
    "            model.to(torch.device(\"cpu\"));\n",
    "\n",
    "            relevance_files = sorted(glob(os.path.join(fold, \"*nii.gz\")))\n",
    "            relevance_maps = load_img(relevance_files)\n",
    "\n",
    "            accs = np.zeros(len(percentages))\n",
    "\n",
    "            for i, frac in enumerate(percentages):\n",
    "                print(fold, i)\n",
    "                occluded, _ = occlude_images(images, relevance_maps, mask, fraction=frac, get_fdata=True)\n",
    "                occluded = np.moveaxis(occluded, -1, 0)\n",
    "                occluded = torch.tensor(occluded).unsqueeze(1)\n",
    "                pred = np.argmax(model(occluded.float()).detach().cpu().numpy(), axis=1)\n",
    "                accs[i] = compute_accuracy(real, pred)\n",
    "                print(accs[i])\n",
    "\n",
    "            df_inter = pd.DataFrame(accs.tolist(), columns=[\"accuracy\"])\n",
    "            df_inter[\"algorithm\"] = algo\n",
    "            df_inter[\"prct_occluded\"] = percentages\n",
    "\n",
    "            df_occlu.append(df_inter)\n",
    "\n",
    "    df_occlusion = pd.concat(df_occlu)\n",
    "    df_occlusion.to_csv(\"stats/occlusion_curves.csv\", index=False)\n",
    "else:\n",
    "    df_occlusion = pd.read_csv(\"stats/occlusion_curves.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d62991-47d5-47b2-a6c2-2eafa2043cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occlusion = pd.concat([df_stacked, df_occlusion])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "sns.scatterplot(ax=ax, data=df_occlusion, x=\"prct_occluded\", y=\"accuracy\", hue=\"algorithm\", alpha=.4, legend=False, zorder=0)\n",
    "sns.lineplot(ax=ax, data=df_occlusion, x=\"prct_occluded\", y=\"accuracy\", hue=\"algorithm\", style=\"algorithm\", \n",
    "             errorbar=(\"ci\", 95), n_boot=1000, linewidth=2, markers=True, markersize=10)\n",
    "ax.axhline(.2, color=\"black\", linestyle=\"--\", zorder=0)\n",
    "ax.legend(frameon=False, loc=\"center right\", fontsize=18, title=\"attribution method\")\n",
    "ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "#plt.savefig(\"figures/occlusion_curves.pdf\", facecolor=fig.get_facecolor(), transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ee22ba-c527-44ce-8fb5-79243bc52d6a",
   "metadata": {},
   "source": [
    "# Compute and investigate mutual information between different combination of attribution- and (group) t-mapssort_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536a9a0c-2967-4a20-923b-c9e707a75fca",
   "metadata": {},
   "source": [
    "Mutual information can help us understand how similar the attribution maps of the LRP or GBP algorithm are to the original data format, i.e., t-statistics maps of single subjects or of the group. \n",
    "\n",
    "We can further perform some sanity checks this way:\n",
    "* Comparing attribution maps obtained by networks trained with real input-label mappings to those with shuffled mappings can tell us something about the sensitivity to network parameters\n",
    "* Comparing attribution maps to t-maps of single subjects or to the group t-maps allows us to judge how well the attribution maps reflect univariate statistics (may not be so fair because CNNs are multivariate!)\n",
    "* We can see whether LRP or GBP has higher better mutual information to the original input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44047831-645e-4b17-a173-f2711845c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from nilearn.masking import apply_mask\n",
    "from nilearn.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064941a-03d7-45c2-bbdd-291ae60f5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = \"stat-maps/motor_mask.nii.gz\"\n",
    "#mask = mni_template\n",
    "#contrasts = [\"subattr-vs-grpattr\", \"subt-vs-grpt\", \"subattr-vs-grpt\", \"grpattr-vs-grpt\"]\n",
    "#contrasts = [\"subattr-vs-grpt\", \"grpattr-vs-grpt\"]\n",
    "contrasts = [\"attr-real-vs-shuffled\"]\n",
    "#contrasts = [\"subattr-vs-subt\"]\n",
    "for i, contrast in enumerate(contrasts):\n",
    "    test = compute_mi(class_labels, mask, \"mi_motor-mask\", n_folds=7, attr_methods=[\"lrp\", \"guidedbackprop\"], contrast=contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f77fbd3-a335-420d-8258-ed6bac697b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it for the trained model vs rnd model\n",
    "contrast = \"model-trained-vs-rnd\"\n",
    "methods = [\"lrp\", \"guidedbackprop\"]\n",
    "seed = 2020\n",
    "\n",
    "fold = best_fold\n",
    "\n",
    "mis_list = []\n",
    "mask = mni_template\n",
    "for m, method in enumerate(methods):\n",
    "    \n",
    "    \n",
    "    for c, lbl in enumerate(class_labels):\n",
    "        X = apply_mask(f\"{method}/model-random/motor_fold-00/{lbl}.nii.gz\", mask)\n",
    "        y = apply_mask(f\"{method}/real/fold-{fold:02d}/{lbl}.nii.gz\", mask)\n",
    "        \n",
    "        mi = np.zeros(len(X))\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            mi[i] = mutual_info_regression(X=X[i, :].reshape(-1, 1), y=y[i, :],\n",
    "                                           discrete_features=False, random_state=seed)\n",
    "        mis_list.append(\n",
    "            pd.DataFrame({\"mi\": mi.tolist(), \"class\": lbl, \"fold\": fold,\n",
    "                          \"attr_method\": method, \"contrast\": contrast}))\n",
    "\n",
    "mis = pd.concat(mis_list)\n",
    "mis.to_csv(f\"stats/mi_motor-mask_{contrast}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49a7ba-7bdc-4410-b827-74fa89a1b151",
   "metadata": {},
   "source": [
    "## Plot the mutual information scores for the sanity checks (i.e., model trained vs model rnd; real labels vs shuffled labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751802a2-3a56-499d-9435-1c1d7367ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10), sharex=True, sharey=True)\n",
    "\n",
    "mis = pd.read_csv(\"stats/mi_whole-brain_attr-real-vs-shuffled.csv\")\n",
    "sns.boxenplot(ax=axes[0], data=mis[mis.fold==best_fold], x=\"class\", y=\"mi\", hue=\"attr_method\")\n",
    "axes[0].set_title(\"data randomization test\");\n",
    "\n",
    "mis = pd.read_csv(\"stats/mi_whole-brain_model-trained-vs-rnd.csv\")\n",
    "sns.boxenplot(ax=axes[1], data=mis, x=\"class\", y=\"mi\", hue=\"attr_method\")\n",
    "axes[1].set_title(\"model randomization test\");\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i == 1:\n",
    "        ax.legend(frameon=False, title=\"attribution method\")\n",
    "    else:\n",
    "        ax.legend([],[], frameon=False)\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "    \n",
    "plt.savefig(\"figures/mi_sanity.pdf\", facecolor=fig.get_facecolor(), transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d2d45e-bb8c-4f54-b9fb-e942233d7b70",
   "metadata": {},
   "source": [
    "## Plot the mutual information scores for different comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2ca94-7c4c-4073-953e-efd55333dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 18\n",
    "MEDIUM_SIZE = 22\n",
    "BIGGER_SIZE = 26\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473f3b5-cd87-4882-a48d-5155e739251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [\"whole-brain\"]#, \"motor-mask\"]\n",
    "best_fold = 3\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 10), sharey=True, gridspec_kw={'width_ratios': [1, 1.3, .8, 1]})\n",
    "\n",
    "# grpAttr vs grpOrig\n",
    "contrast = \"grpattr-vs-grpt\"\n",
    "df = pd.read_csv(f\"stats/mi_whole-brain_{contrast}.csv\")\n",
    "df = df[df.fold==best_fold]\n",
    "sns.barplot(ax=axes[0], data=df, x=\"class\", y=\"mi\", hue=\"attr_method\")\n",
    "axes[0].set_ylabel(\"$MI_{(GrpMethod, GrpT)}$\")\n",
    "axes[0].set_xticklabels(class_labels, rotation=45)\n",
    "\n",
    "# subattr-vs-subt\n",
    "contrast = \"subattr-vs-subt\"\n",
    "df = pd.read_csv(f\"stats/mi_whole-brain_{contrast}.csv\")\n",
    "df = df[df.fold==best_fold]\n",
    "df = df.replace(\"guidedbackprop\", \"gbp\")\n",
    "sns.boxenplot(ax=axes[1], data=df, x=\"class\", hue=\"attr_method\", y=\"mi\", k_depth=\"trustworthy\")\n",
    "axes[1].set_ylabel(\"$MI_{(SubMethod, SubT)}$\")\n",
    "axes[1].set_xticklabels(class_labels, rotation=45)\n",
    "\n",
    "# average\n",
    "sns.boxenplot(ax=axes[2], data=df, x=\"attr_method\", y=\"mi\", k_depth=\"trustworthy\")\n",
    "axes[2].set_ylabel(\"$MI_{(SubMethod, SubT)}$\")\n",
    "axes[2].set_xticklabels(df[\"attr_method\"].unique(), rotation=45)\n",
    "\n",
    "# subattr-vs-grpattr\n",
    "contrast = \"subattr-vs-grpattr\"\n",
    "df = pd.read_csv(f\"stats/mi_whole-brain_{contrast}.csv\")\n",
    "df = df[df.fold==best_fold]\n",
    "df = df.replace(\"guidedbackprop\", \"gbp\")\n",
    "\n",
    "df2 = pd.read_csv(\"stats/mi_whole-brain_subt-vs-grpt.csv\")\n",
    "\n",
    "test = pd.concat([df, df2])\n",
    "sns.boxenplot(ax=axes[3], data=test, x=\"attr_method\", y=\"mi\", k_depth=\"trustworthy\")\n",
    "axes[3].set_ylabel(\"$MI_{(SubMethod, GrpMethod)}$\")\n",
    "#axes[3].set_xticklabels(class_labels, rotation=45)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i == 1:\n",
    "        ax.legend(frameon=False, title=\"attribution method\")\n",
    "    else:\n",
    "        ax.legend([],[], frameon=False)\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(\"figures/mi_whole-brain.pdf\", facecolor=fig.get_facecolor(), transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80374eaf-5160-4a2d-9106-325f313110ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8dcdf-106f-4954-8299-4f3ae89f87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [\"whole-brain\"]#, \"motor-mask\"]\n",
    "best_fold = 3\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 10), sharey=True, gridspec_kw={'width_ratios': [1, 1.3, .8]})\n",
    "\n",
    "for i, m in enumerate(masks):\n",
    "    # grpAttr vs grpOrig\n",
    "    contrast = \"grpattr-vs-grpt\"\n",
    "    df = pd.read_csv(f\"stats/mi_{m}_{contrast}.csv\")\n",
    "    df = df[df.fold==best_fold]\n",
    "    sns.barplot(ax=axes[0], data=df, x=\"class\", y=\"mi\", hue=\"attr_method\")\n",
    "    axes[i].set_ylabel(\"$MI_{(GrpMethod, GrpT)}$\")\n",
    "    axes[i].set_xticklabels(class_labels, rotation=45)\n",
    "\n",
    "    # sub vs grp\n",
    "    contrast = \"subattr-vs-subt\"\n",
    "    dfs = []\n",
    "    this_df = pd.read_csv(f\"stats/mi_{m}_{contrast}.csv\")\n",
    "    # filter for best fold\n",
    "    best_fold_df = this_df[this_df.fold == best_fold].copy()\n",
    "    dfs.append(best_fold_df)\n",
    "    dfs[0][\"contrast\"] = contrast\n",
    "\n",
    "    dfs.append(pd.read_csv(f\"stats/mi_{m}_subt-vs-grpt.csv\"))\n",
    "    dfs[-1][\"contrast\"] = \"subattr-vs-subt\"\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.replace(\"guidedbackprop\", \"gbp\")\n",
    "    sns.boxenplot(ax=axes[1], data=df, x=\"class\", hue=\"attr_method\", y=\"mi\", k_depth=\"trustworthy\")\n",
    "    axes[1].set_ylabel(\"$MI_{(SubMethod, GrpMethod)}$\")\n",
    "    axes[1].set_xticklabels(class_labels, rotation=45)\n",
    "    \n",
    "    \n",
    "    sns.boxenplot(ax=axes[2], data=df, x=\"attr_method\", y=\"mi\", k_depth=\"trustworthy\")\n",
    "    axes[2].set_ylabel(\"$MI_{(SubMethod, GrpMethod)}$\")\n",
    "    axes[2].set_xticklabels(df[\"attr_method\"].unique(), rotation=45)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i == 1:\n",
    "        ax.legend(frameon=False, title=\"attribution method\")\n",
    "    else:\n",
    "        ax.legend([],[], frameon=False)\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(\"figures/mi_two-masks.pdf\", facecolor=fig.get_facecolor(), transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352e9d9-f6f2-4bb6-80ab-716d218b579a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
