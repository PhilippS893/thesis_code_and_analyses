{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaef949e-51bd-438b-9803-d58970cfd6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from delphi.networks.ConvNets import BrainStateClassifier3d\n",
    "from delphi.utils.datasets import NiftiDataset\n",
    "from delphi.utils.tools import ToTensor, compute_accuracy, convert_wandb_config, read_config\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f59b2d2-f6c5-425c-836b-7e596e392fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    import random\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    g = torch.Generator()  # can be used in pytorch dataloaders for reproducible sample selection when shuffle=True\n",
    "    g.manual_seed(seed)\n",
    "\n",
    "    return g\n",
    "\n",
    "g = set_random_seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b01b8e-62ca-4ea9-bd01-34c6444f75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_plots(y_true, y_pred, y_prob, class_labels, dataset):\n",
    "    wandb.log({\n",
    "        f\"{dataset}-ROC\": wandb.plot.roc_curve(y_true=y_true, y_probas=y_prob, labels=class_labels),\n",
    "        f\"{dataset}-PR\": wandb.plot.pr_curve(y_true=y_true, y_probas=y_prob, labels=class_labels),\n",
    "        f\"{dataset}-ConfMat\": wandb.plot.confusion_matrix(y_true=y_true, preds=y_pred, class_names=class_labels)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3121c-e2da-4b4a-b20a-01c76f0b4604",
   "metadata": {},
   "source": [
    "# Define the classes and data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b653d2-d91b-4c98-9e1b-d14ed5ceb30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = sorted([\"handleft\", \"handright\", \"footleft\", \"footright\", \"tongue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "039d2540-9c71-4c0b-aaea-e50d5c7792ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = NiftiDataset(\"../t-maps/test\", class_labels, 0, device=DEVICE, transform=ToTensor())\n",
    "\n",
    "# we will split the train dataset into a train (80%) and validation (20%) set.\n",
    "data_train_full = NiftiDataset(\"../t-maps/train\", class_labels, 0, device=DEVICE, transform=ToTensor())\n",
    "\n",
    "# we want one stratified shuffled split\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2020)\n",
    "idx_train, idx_valid = next(sss.split(data_train_full.data, data_train_full.labels))\n",
    "\n",
    "data_train = torch.utils.data.Subset(data_train_full, idx_train)\n",
    "data_valid = torch.utils.data.Subset(data_train_full, idx_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330748c0-72f0-4748-b7be-eeee278d0904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "459a3075-55b9-46a1-81c7-7fbd2d3646ba",
   "metadata": {},
   "source": [
    "# Set up the sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52c0ce-26e1-4eb9-81d9-e5266ea7e9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38759e91-e10c-47cc-a639-98d03e581869",
   "metadata": {},
   "source": [
    "# Define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97713ef2-507d-4776-a0b9-986d123502d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(model, config, save_name, logwandb=True):\n",
    "    \n",
    "    dl_test = DataLoader(data_test, batch_size=config.batch_size, shuffle=True, generator=g)\n",
    "    dl_train = DataLoader(data_train, batch_size=config.batch_size, shuffle=True, generator=g)\n",
    "    dl_valid = DataLoader(data_valid, batch_size=config.batch_size, shuffle=True, generator=g)\n",
    "    \n",
    "    best_loss, best_acc = 100, 0\n",
    "    loss_acc = []\n",
    "    train_stats, valid_stats = [], []\n",
    "    \n",
    "    # loop for the above set number of epochs\n",
    "    for epoch in range(0, config.epochs):\n",
    "        _, _ = model.fit(dl_train, lr=config.learning_rate, device=DEVICE)\n",
    "\n",
    "        # for validating or testing set the network into evaluation mode such that layers like dropout are not active\n",
    "        with torch.no_grad():\n",
    "            tloss, tstats = model.fit(dl_train, device=DEVICE, train=False)\n",
    "            vloss, vstats = model.fit(dl_valid, device=DEVICE, train=False)\n",
    "                    \n",
    "        tacc = compute_accuracy(tstats[:, -2], tstats[:, -1])\n",
    "        vacc = compute_accuracy(vstats[:, -2], vstats[:, -1])\n",
    "\n",
    "        loss_acc.append(pd.DataFrame([[tloss, vloss, tacc, vacc]],\n",
    "                                     columns=[\"train_loss\", \"valid_loss\", \"train_acc\", \"valid_acc\"]))\n",
    "        \n",
    "        train_stats.append(pd.DataFrame(tstats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]]))\n",
    "        train_stats[epoch][\"epoch\"] = epoch\n",
    "        valid_stats.append(pd.DataFrame(vstats.tolist(), columns=[*class_labels, *[\"real\", \"predicted\"]]))\n",
    "        valid_stats[epoch][\"epoch\"] = epoch\n",
    "        \n",
    "        wandb.log({\n",
    "            \"train_acc\": tacc, \"train_loss\": tloss,\n",
    "            \"valid_acc\": vacc, \"valid_loss\": vloss\n",
    "        })\n",
    "        \n",
    "        print('Epoch=%03d, train_loss=%2.3f, train_acc=%1.3f, valid_loss=%2.3f, valid_acc=%1.3f' % \n",
    "             (epoch, tloss, tacc, vloss, vacc))\n",
    "        \n",
    "        if (vacc >= best_acc) and (vloss <= best_loss):\n",
    "            # assign the new best values\n",
    "            best_acc, best_loss = vacc, vloss\n",
    "            wandb.run.summary[\"best_valid_accuracy\"] = best_acc\n",
    "            wandb.run.summary[\"best_valid_epoch\"] = epoch\n",
    "            # save the current best model\n",
    "            model.save(save_name)\n",
    "            # plot some graphs for the validation data\n",
    "            wandb_plots(vstats[:, -2], vstats[:, -1], vstats[:, :-2], class_labels, \"valid\")\n",
    "\n",
    "    # save the files\n",
    "    full_df = pd.concat(loss_acc)\n",
    "    full_df.to_csv(os.path.join(save_name, \"loss_acc_curves.csv\"), index=False)\n",
    "    full_df = pd.concat(train_stats)\n",
    "    full_df.to_csv(os.path.join(save_name, \"train_stats.csv\"), index=False)\n",
    "    full_df = pd.concat(valid_stats)\n",
    "    full_df.to_csv(os.path.join(save_name, \"valid_stats.csv\"), index=False)\n",
    "    \n",
    "    # EVALUATE THE MODEL ON THE TEST DATA\n",
    "    with torch.no_grad():\n",
    "        testloss, teststats = model.fit(dl_test, train=False)\n",
    "    testacc = compute_accuracy(teststats[:, -2], teststats[:, -1])\n",
    "    wandb.run.summary[\"test_accuracy\"] = testacc\n",
    "\n",
    "    wandb.log({\"test_accuraccy\": testacc, \"test_oss\": testloss})\n",
    "    wandb_plots(teststats[:, -2], teststats[:, -1], teststats[:, :-2], class_labels, \"test\")\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e36224-393e-483d-b4a5-c08cde65d39e",
   "metadata": {},
   "source": [
    "# Define the run_train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94e68c98-e95d-4c3e-8018-1a098091139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training function with the wandb init\n",
    "def run_train():\n",
    "    \n",
    "    # here we initialize weights&biases. \n",
    "    with wandb.init() as run:\n",
    "        # here's the promised conversion of the wandb.config\n",
    "        # this results into a dict that contains key-value pairs that we can use to configure our network:\n",
    "        # converted_config['lin_neurons'] = [512, 8, 128]\n",
    "                \n",
    "        converted_config = convert_wandb_config(wandb.config, BrainStateClassifier3d._REQUIRED_PARAMS)\n",
    "                \n",
    "        model = BrainStateClassifier3d((91, 109, 91), len(class_labels), converted_config)\n",
    "        \n",
    "        # We do not necessarily need this line but it is nice to update the config.\n",
    "        #wandb.config.update(model.config, allow_val_change=True)\n",
    "        \n",
    "        t_stamp = time.time()\n",
    "        save_name = os.path.join(\"models\", f\"motor-explo_{t_stamp}\")\n",
    "        wandb.run.name = f\"motor-explo-{t_stamp}\"\n",
    "        \n",
    "        # now train the netwok, yay!\n",
    "        train_net(model, wandb.config, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0238daa7-5ceb-4add-9ded-4ec9d76511d4",
   "metadata": {},
   "source": [
    "# Run the sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d8f830-d28c-4ef1-a24a-91c1cbd462c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'exploration-sweep', 'entity': 'philis893', 'project': 'thesis', 'method': 'grid', 'metric': {'name': 'valid_acc'}, 'parameters': {'channels1': {'value': 1}, 'channels2': {'value': 8}, 'channels3': {'value': 16}, 'channels4': {'value': 32}, 'channels5': {'value': 64}, 'kernel_size': {'values': [3, 5, 7]}, 'lin_neurons1': {'value': 128}, 'lin_neurons2': {'value': 64}, 'batch_size': {'values': [4, 8, 16, 32]}, 'dropout': {'values': [0.3, 0.4, 0.5, 0.6, 0.7]}, 'learning_rate': {'values': [1e-05, 0.0001, 0.001]}, 'epochs': {'value': 60}}}\n"
     ]
    }
   ],
   "source": [
    "sweep_config = read_config(\"exploration_sweep.yaml\")\n",
    "print(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1d5adb-7b16-4081-9ae2-eda6dd19333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: d6637pnp\n",
      "Sweep URL: https://wandb.ai/philis893/thesis/sweeps/d6637pnp\n"
     ]
    }
   ],
   "source": [
    "# set the wandb sweep config\n",
    "#os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_ENTITY'] = \"philis893\" # this is my wandb account name. This can also be a group name, for example\n",
    "os.environ['WANDB_PROJECT'] = \"thesis\" # this is simply the project name where we want to store the sweep logs and plots\n",
    "sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee61b9-76f4-484b-87a7-5b55732f5a98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3srdrt68 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchannels1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchannels2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchannels3: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchannels4: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchannels5: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlin_neurons1: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlin_neurons2: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mphilis893\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/phisei/Documents/phd/thesis_code_and_analyses/hp_exploration/wandb/run-20221006_111037-3srdrt68</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/philis893/thesis/runs/3srdrt68\" target=\"_blank\">dazzling-sweep-1</a></strong> to <a href=\"https://wandb.ai/philis893/thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/philis893/thesis/sweeps/d6637pnp\" target=\"_blank\">https://wandb.ai/philis893/thesis/sweeps/d6637pnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01332712173461914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f672deaee847ce8a85cb95e67de1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010349035263061523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1c14fdfc1c4720a2e3b1c1e95acbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010474920272827148,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c771da622fe4aedb61c2130dc925cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=000, train_loss=1.603, train_acc=0.202, valid_loss=1.604, valid_acc=0.200\n",
      "Saving models/motor-explo_1665047443.934973/state_dict.pth\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01727008819580078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58c128fa8154b9aaa8ec915cd9f2ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009943962097167969,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9084966df64741a2557875a896f892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count=10\n",
    "wandb.agent(sweep_id, function=run_train, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00948e00-9286-46e9-aa79-45cf64ab5b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51fe2a-de78-48a3-9243-8799ceed1f18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
