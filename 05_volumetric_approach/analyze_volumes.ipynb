{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc9b9228-94ae-4d49-ac7a-9e14bf84ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db52d71-90b5-4ede-bd5d-ccbb72dac446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os, wandb, torch, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from delphi import mni_template\n",
    "from delphi.networks.ConvNets import BrainStateClassifier3d\n",
    "from delphi.utils.datasets import NiftiDataset\n",
    "from delphi.utils.tools import ToTensor, compute_accuracy, convert_wandb_config, read_config, z_transform_volume, save_in_mni\n",
    "from delphi.utils.plots import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# you can find all these files in ../utils\n",
    "from utils.tools import attribute_with_method, concat_stat_files, compute_mi\n",
    "from utils.wandb_funcs import reset_wandb_env, wandb_plots\n",
    "from utils.random import set_random_seed\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from captum.attr import GuidedBackprop\n",
    "from zennit.rules import Epsilon, Gamma, Pass\n",
    "from zennit.types import Convolution, Linear, Activation\n",
    "from zennit.composites import LayerMapComposite\n",
    "from utils.tools import attribute_with_method\n",
    "\n",
    "composite_lrp_map = [\n",
    "    (Activation, Pass()),\n",
    "    (Convolution, Gamma(gamma=.25)),\n",
    "    (Linear, Epsilon(epsilon=0)),\n",
    "]\n",
    "\n",
    "LRP = LayerMapComposite(\n",
    "    layer_map=composite_lrp_map,\n",
    ")\n",
    "LRP.__name__ = 'LRP'\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "g = set_random_seed(2020) # the project started in the year 2020, hence the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12086f04-b8ab-47f6-b668-0b76007ac7bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from config file models/vol-wm-classifier-withrest_fold-02//config.yaml\n",
      "Running lrp on body\n",
      "Saving lrp/wm/body.nii.gz\n",
      "Saving lrp/wm/avg/body.nii.gz\n",
      "Running lrp on face\n",
      "Saving lrp/wm/face.nii.gz\n",
      "Saving lrp/wm/avg/face.nii.gz\n",
      "Running lrp on place\n",
      "Saving lrp/wm/place.nii.gz\n",
      "Saving lrp/wm/avg/place.nii.gz\n",
      "Running lrp on rest_WM\n",
      "Saving lrp/wm/rest_WM.nii.gz\n",
      "Saving lrp/wm/avg/rest_WM.nii.gz\n",
      "Running lrp on tool\n",
      "Saving lrp/wm/tool.nii.gz\n",
      "Saving lrp/wm/avg/tool.nii.gz\n",
      "Loading from config file models/vol-wm-classifier-withrest_fold-02//config.yaml\n",
      "Running guidedbackprop on body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philippseidel/anaconda3/envs/thesis-env/lib/python3.8/site-packages/captum/attr/_core/guided_backprop_deconvnet.py:64: UserWarning: Setting backward hooks on ReLU activations.The hooks will be removed after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving guidedbackprop/wm/body.nii.gz\n",
      "Saving guidedbackprop/wm/avg/body.nii.gz\n",
      "Running guidedbackprop on face\n",
      "Saving guidedbackprop/wm/face.nii.gz\n",
      "Saving guidedbackprop/wm/avg/face.nii.gz\n",
      "Running guidedbackprop on place\n",
      "Saving guidedbackprop/wm/place.nii.gz\n",
      "Saving guidedbackprop/wm/avg/place.nii.gz\n",
      "Running guidedbackprop on rest_WM\n",
      "Saving guidedbackprop/wm/rest_WM.nii.gz\n",
      "Saving guidedbackprop/wm/avg/rest_WM.nii.gz\n",
      "Running guidedbackprop on tool\n",
      "Saving guidedbackprop/wm/tool.nii.gz\n",
      "Saving guidedbackprop/wm/avg/tool.nii.gz\n"
     ]
    }
   ],
   "source": [
    "attributor_method = [LRP, GuidedBackprop]\n",
    "#volume_model_path = \"../05_volumetric_approach/models/vol-motor-classifier-withrest_fold-09\"\n",
    "volume_model_path = \"models/vol-wm-classifier-withrest_fold-02/\"\n",
    "\n",
    "TASK_LABEL = 'wm'\n",
    "\n",
    "for i, method in enumerate(attributor_method):\n",
    "\n",
    "    method_name = str(method.__name__).lower()\n",
    "\n",
    "    # load the trained network\n",
    "    \n",
    "    model = BrainStateClassifier3d(volume_model_path)\n",
    "    model.to(torch.device(\"cpu\"));\n",
    "    model.eval()\n",
    "\n",
    "    class_labels = model.config['class_labels']\n",
    "    \n",
    "    out_dir_name = f\"{method_name}/{TASK_LABEL}\"\n",
    "    if not os.path.exists(out_dir_name):\n",
    "        os.makedirs(out_dir_name)\n",
    "\n",
    "    for j in range(model.config[\"n_classes\"]):\n",
    "\n",
    "        print(f\"Running {method_name} on {class_labels[j]}\")\n",
    "\n",
    "        out_fname = os.path.join(out_dir_name, '%s.nii.gz' % class_labels[j])\n",
    "        if os.path.isfile(out_fname):\n",
    "            print(f\"{out_fname} already exists. Skipping\")\n",
    "            continue\n",
    "\n",
    "        dl = DataLoader(\n",
    "            NiftiDataset('../v-maps/test/', [class_labels[j]], 0, device=torch.device(\"cpu\"), transform=ToTensor()),\n",
    "            batch_size=20, shuffle=False, num_workers=0\n",
    "        )\n",
    "\n",
    "        for i, (volume, target) in enumerate(dl):\n",
    "\n",
    "            attribution = attribute_with_method(method, model, volume, target)\n",
    "\n",
    "            subject_attr = np.moveaxis(attribution.squeeze().detach().numpy(), 0, -1)\n",
    "            subject_attr = z_transform_volume(subject_attr)\n",
    "            avg_attr = subject_attr.mean(axis=-1)\n",
    "\n",
    "        save_in_mni(subject_attr, out_fname)\n",
    "\n",
    "        avg_out_name = os.path.join(out_dir_name, \"avg\")\n",
    "        if not os.path.exists(avg_out_name):\n",
    "            os.makedirs(avg_out_name)\n",
    "        save_in_mni(avg_attr, os.path.join(avg_out_name, '%s.nii.gz' % class_labels[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953a35a4-6e83-4718-9e2f-ea2e5094c8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lrp/multi/avg/body.nii.gz',\n",
       " 'lrp/multi/avg/face.nii.gz',\n",
       " 'lrp/multi/avg/footleft.nii.gz',\n",
       " 'lrp/multi/avg/footright.nii.gz',\n",
       " 'lrp/multi/avg/handleft.nii.gz',\n",
       " 'lrp/multi/avg/handright.nii.gz',\n",
       " 'lrp/multi/avg/match.nii.gz',\n",
       " 'lrp/multi/avg/mental.nii.gz',\n",
       " 'lrp/multi/avg/place.nii.gz',\n",
       " 'lrp/multi/avg/relation.nii.gz',\n",
       " 'lrp/multi/avg/rest_MOTOR.nii.gz',\n",
       " 'lrp/multi/avg/rest_RELATIONAL.nii.gz',\n",
       " 'lrp/multi/avg/rest_SOCIAL.nii.gz',\n",
       " 'lrp/multi/avg/rest_WM.nii.gz',\n",
       " 'lrp/multi/avg/rnd.nii.gz',\n",
       " 'lrp/multi/avg/tongue.nii.gz',\n",
       " 'lrp/multi/avg/tool.nii.gz']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltools.data import Brain_Data\n",
    "import glob\n",
    "\n",
    "files = sorted(glob.glob(\"lrp/multi/avg/*.nii.gz\"))\n",
    "test = Brain_Data(files, mask=mni_template)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7db97b5-b2eb-4ee6-969b-1a22243b990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philippseidel/anaconda3/envs/thesis-env/lib/python3.8/site-packages/nltools/plotting.py:77: UserWarning: Percentile thresholding ignores brain mask. Results are likely more liberal than you expect (e.g. with non-interactive plotting)!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7309d8e1c7154e31bf55dd4568857108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatText(value=95.0, description='Threshold'), IntSlider(value=0, continuous_update=Falâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.iplot(threshold=\"95%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39070bd-eb27-4fff-a951-01be19c91ed9",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae97235a-8d14-4d59-b1cd-6a1ff9164332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['handleft',\n",
       " 'handright',\n",
       " 'footleft',\n",
       " 'footright',\n",
       " 'tongue',\n",
       " 'rest_MOTOR',\n",
       " 'rest_RELATIONAL',\n",
       " 'face',\n",
       " 'body',\n",
       " 'place',\n",
       " 'tool',\n",
       " 'rest_SOCIAL',\n",
       " 'rest_WM',\n",
       " 'match',\n",
       " 'relation',\n",
       " 'mental',\n",
       " 'rnd']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "from nilearn.image import load_img, smooth_img\n",
    "from nilearn.masking import apply_mask, unmask\n",
    "from delphi import mni_template\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mask = load_img(mni_template)\n",
    "data_dir_train = glob(os.path.join(\"../v-maps/train\", \"*\"))\n",
    "classes = [os.path.split(x)[-1] for i, x in enumerate(data_dir_train)]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d1a575-559a-4808-9278-820809fead83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121f8676ae5b4c4d8280725f1c85f86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006f16c61dc84bec8da5f0321081a74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d17f4834b34f5e872d540abbdd6da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb127e3733f42ad9beda7c5bb512192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ed95b6393247a19bedc0dad41e5580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397de29f76604529acdb0f2d4fb21be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a036789ff7a2427499bcf8d56a9bbc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444b7d1292b14f29a6a000dae6439ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba71239d8a94a5199b5fdf053d3fafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4697cb1b1f4c19b58d383ea8105154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa2ed9320d84a4ea5a09f4927cd18f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fffcd1645e4f16afe0caca2a15147d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d2859b996f4dccad6526825554d1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56af10cbfb0b4b90a7a349172688f2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8629db75dec647eda87e53df14abd89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d82296c9f0b4bb28a2402db6bba8d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98921edcf4143f89779ff25c2befced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "img: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fwhm=4\n",
    "\n",
    "for c, cl in enumerate(data_dir_train):\n",
    "    \n",
    "    imgs = glob(os.path.join(cl, \"*.nii.gz\"))\n",
    "    out_dir = os.path.join(f\"../v-smoothed/train/{classes[c]}\")\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "    for i, img in tqdm(enumerate(imgs), desc=\"img\"):\n",
    "        \n",
    "        out_name = os.path.join(out_dir, os.path.split(img)[-1])\n",
    "        img_dat = load_img(img)\n",
    "        smoothed = unmask(apply_mask(smooth_img(img_dat, fwhm=fwhm), mask), mask)\n",
    "        smoothed.to_filename(out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c949a28-b3e7-4739-b2a8-655915184fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
